# ğŸ”„ Pipeline æ¶æ„æ–‡æ¡£

> **ç›®æ ‡è¯»è€…**ï¼šæ–°æ‰‹å¼€å‘è€…
> **ç”¨é€”**ï¼šç†è§£ Pipeline æ˜¯ä»€ä¹ˆã€å¦‚ä½•ç¼–æ’å·¥ä½œæµã€å¦‚ä½•æ‰§è¡Œ

---

## ğŸ¯ ä¸€å¥è¯æ¦‚æ‹¬

**Pipeline æ˜¯ä¸€ä¸ª"å·¥ä½œæµç¼–æ’å¼•æ“"** â€”â€” æŠŠå¤šä¸ªæ–¹æ³•æŒ‰ä¾èµ–å…³ç³»ä¸²è”æˆæµæ°´çº¿ï¼Œè‡ªåŠ¨å¤„ç†æ•°æ®ä¼ é€’ã€ç¼“å­˜ã€é‡è¯•ã€å¹¶è¡Œæ‰§è¡Œã€‚

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒæ€æƒ³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      YAML é…ç½®æ–‡ä»¶                            â”‚
â”‚  steps:                                                     â”‚
â”‚    step1: get_data â†’ output: raw_data                      â”‚
â”‚    step2: clean_data(raw_data) â†’ output: clean_data       â”‚
â”‚    step3: analyze(clean_data) â†’ output: result            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ExecuteManager                            â”‚
â”‚  è§£æ YAML â†’ æ„å»ºèŠ‚ç‚¹ â†’ æ‹“æ‰‘æ’åº â†’ æ‰§è¡Œå·¥ä½œæµ                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æœåŠ¡å±‚ï¼ˆè§£è€¦è®¾è®¡ï¼‰                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ConfigService â”‚  â”‚FlowExecutor  â”‚  â”‚Result        â”‚     â”‚
â”‚  â”‚é…ç½®è§£æ      â”‚  â”‚æµç¨‹æ‰§è¡Œ      â”‚  â”‚Assembler     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æ‰§è¡Œå¼•æ“å±‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚KedroEngine   â”‚ å°è£…äº  â”‚PrefectEngine â”‚                 â”‚
â”‚  â”‚èŠ‚ç‚¹æ‰§è¡Œ      â”‚ â†â”€â”€â”€â”€â”€â”€ â”‚æµç¨‹å°è£…      â”‚                 â”‚
â”‚  â”‚ç¼“å­˜ç®¡ç†      â”‚         â”‚å¤±è´¥é‡è¯•      â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Orchestrator                              â”‚
â”‚  åŠ¨æ€è°ƒç”¨å·²æ³¨å†Œçš„æ–¹æ³•ï¼ˆget_data, clean_data, analyze...ï¼‰   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ ç›®å½•ç»“æ„

```
pipeline/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ main.py                    # CLI å…¥å£ï¼ˆpython -m pipeline.mainï¼‰
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ pipeline.yaml          # Pipeline é…ç½®ç¤ºä¾‹
â”‚   â””â”€â”€ tushare_fina.yaml      # ç‰¹å®šåœºæ™¯é…ç½®
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ execute_manager.py     # ä¸»ç®¡ç†å™¨ï¼ˆåè°ƒæ‰€æœ‰æœåŠ¡ï¼‰
â”‚   â”œâ”€â”€ context.py             # PipelineContextï¼ˆå…±äº«çŠ¶æ€å®¹å™¨ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ protocols/             # æ¥å£æŠ½è±¡ï¼ˆé¿å…å¾ªç¯ä¾èµ–ï¼‰
â”‚   â”‚   â””â”€â”€ method_handle_protocol.py
â”‚   â”‚
â”‚   â”œâ”€â”€ handles/               # æ–¹æ³•å¥æŸ„ï¼ˆå»¶è¿Ÿç»‘å®šï¼‰
â”‚   â”‚   â””â”€â”€ method_handle.py
â”‚   â”‚
â”‚   â””â”€â”€ services/              # æœåŠ¡å±‚ï¼ˆèŒè´£åˆ†ç¦»ï¼‰
â”‚       â”œâ”€â”€ config_service.py           # é…ç½®è§£æã€æ‹“æ‰‘æ’åº
â”‚       â”œâ”€â”€ flow_executor.py            # æµç¨‹æ‰§è¡Œ
â”‚       â”œâ”€â”€ result_assembler.py         # ç»“æœç»„è£…
â”‚       â”œâ”€â”€ runtime_param_service.py    # å‚æ•°è§£æ
â”‚       â”œâ”€â”€ cache_stats_service.py      # ç¼“å­˜ç»Ÿè®¡
â”‚       â””â”€â”€ hook_manager.py             # Hook äº‹ä»¶ç®¡ç†
â”‚
â””â”€â”€ engines/
    â”œâ”€â”€ kedro_engine.py        # Kedro æ‰§è¡Œå¼•æ“ï¼ˆæ ¸å¿ƒï¼‰
    â””â”€â”€ prefect_engine.py      # Prefect æµç¨‹å¼•æ“ï¼ˆå°è£… Kedroï¼‰
```

---

## ğŸ”„ å·¥ä½œæµç¨‹

### 1ï¸âƒ£ é…ç½®å®šä¹‰ï¼ˆç”¨æˆ·ï¼‰

ç”¨æˆ·é€šè¿‡ YAML å®šä¹‰å·¥ä½œæµï¼š

```yaml
# pipeline/configs/my_pipeline.yaml
pipeline:
  name: stock_analysis
  description: è‚¡ç¥¨æ•°æ®åˆ†ææµæ°´çº¿

  steps:
    # Step 1: è·å–æ•°æ®
    step1:
      component: datahub
      methods:
        - get_data
      parameters:
        stock_code: "000001.SZ"
      outputs:
        - name: raw_data
          type: dataset  # dataset = DataFrameï¼Œä¼šè¢« Kedro ç®¡ç†

    # Step 2: æ¸…æ´—æ•°æ®ï¼ˆä¾èµ– step1 çš„è¾“å‡ºï¼‰
    step2:
      component: data_engines
      methods:
        - clean_data
      parameters:
        data: "steps.step1.outputs.parameters.raw_data"  # å¼•ç”¨ step1 è¾“å‡º
      outputs:
        - name: clean_data
          type: dataset

    # Step 3: åˆ†ææ•°æ®ï¼ˆä¾èµ– step2 çš„è¾“å‡ºï¼‰
    step3:
      component: business_engines
      methods:
        - analyze_trend
      parameters:
        data: "steps.step2.outputs.parameters.clean_data"
      outputs:
        - name: result
          type: parameter  # parameter = ç®€å•å€¼ï¼ˆdict/list/strï¼‰
```

**å…³é”®æ¦‚å¿µ**ï¼š

| å­—æ®µ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **component** | ç»„ä»¶ç±»å‹ï¼ˆå¯¹åº” orchestratorï¼‰ | datahub, data_engines |
| **methods** | æ–¹æ³•åˆ—è¡¨ï¼ˆé“¾å¼è°ƒç”¨ï¼‰ | [get_data] æˆ– [method1, method2] |
| **parameters** | è¾“å…¥å‚æ•°ï¼ˆæ”¯æŒå¼•ç”¨å…¶ä»–æ­¥éª¤è¾“å‡ºï¼‰ | stock_code: "000001.SZ" |
| **outputs** | è¾“å‡ºå®šä¹‰ï¼ˆdataset/parameterï¼‰ | name: raw_data, type: dataset |

---

### 2ï¸âƒ£ è§£æé…ç½®ï¼ˆConfigServiceï¼‰

**èŒè´£**ï¼š
- åŠ è½½ YAML é…ç½®
- è§£ææ­¥éª¤ä¾èµ–å…³ç³»
- æ‹“æ‰‘æ’åºï¼ˆç¡®å®šæ‰§è¡Œé¡ºåºï¼‰
- æ„å»º Kedro èŠ‚ç‚¹é…ç½®

**æµç¨‹**ï¼š

```python
# ConfigService.load_config()
config = yaml.safe_load(open("pipeline.yaml"))

# ConfigService._parse_steps()
steps = {
    "step1": {...},
    "step2": {
        "depends_on": ["step1"],  # ä¾èµ– step1ï¼ˆé€šè¿‡å¼•ç”¨è‡ªåŠ¨æ£€æµ‹ï¼‰
        ...
    },
    "step3": {
        "depends_on": ["step2"],  # ä¾èµ– step2
        ...
    }
}

# ConfigService._compute_execution_order()
execution_order = ["step1", "step2", "step3"]  # æ‹“æ‰‘æ’åºç»“æœ
```

**ä¾èµ–æ£€æµ‹**ï¼šè‡ªåŠ¨è¯†åˆ«å¼•ç”¨å…³ç³»

```yaml
parameters:
  data: "steps.step1.outputs.parameters.raw_data"
         ^^^^^^ è‡ªåŠ¨æ£€æµ‹åˆ°ä¾èµ– step1
```

---

### 3ï¸âƒ£ æ„å»ºèŠ‚ç‚¹ï¼ˆConfigService + MethodHandleï¼‰

**èŒè´£**ï¼šå°†æ¯ä¸ª step è½¬æ¢ä¸º Kedro èŠ‚ç‚¹é…ç½®

**MethodHandle æœºåˆ¶**ï¼š

> **ä¸ºä»€ä¹ˆéœ€è¦ MethodHandleï¼Ÿ**
> å› ä¸ºåœ¨é…ç½®è§£æé˜¶æ®µï¼Œorchestrator çš„æ–¹æ³•è¿˜æ²¡æœ‰æ³¨å†Œå®Œæˆï¼ˆå¾ªç¯ä¾èµ–é—®é¢˜ï¼‰ã€‚MethodHandle å®ç°"å»¶è¿Ÿç»‘å®š"ï¼šé…ç½®æ—¶åªè®°å½•æ–¹æ³•ä¿¡æ¯ï¼Œæ‰§è¡Œæ—¶æ‰çœŸæ­£è°ƒç”¨ orchestratorã€‚

```python
# ConfigService.build_auto_nodes()
for step_name, step_spec in steps.items():
    # ä¸ºæ¯ä¸ªæ–¹æ³•åˆ›å»º MethodHandleï¼ˆå»¶è¿Ÿç»‘å®šï¼‰
    method_handles = [
        create_method_handle(
            component=step_spec.component,
            method=method_name,
            prefer="auto"  # è®© orchestrator è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å®ç°
        )
        for method_name in step_spec.methods
    ]

    # æ„å»º Kedro èŠ‚ç‚¹é…ç½®
    node_config = {
        "name": step_name,
        "component": step_spec.component,
        "methods": step_spec.methods,
        "method_handles": method_handles,  # å»¶è¿Ÿç»‘å®š
        "inputs": [...],
        "outputs": [...],
        "parameters": {...}
    }
```

---

### 4ï¸âƒ£ æ‰§è¡Œæµç¨‹ï¼ˆFlowExecutor + Enginesï¼‰

#### æ‰§è¡Œå±‚æ¬¡

```
FlowExecutor (æµç¨‹åè°ƒ)
    â†“
PrefectEngine (å¤±è´¥é‡è¯•ã€è½¯å¤±è´¥)
    â†“
KedroEngine (èŠ‚ç‚¹æ‰§è¡Œã€ç¼“å­˜ã€è¡€ç¼˜)
    â†“
MethodHandle.execute() (è°ƒç”¨ orchestrator)
    â†“
Orchestrator.execute() (åŠ¨æ€è°ƒç”¨æ³¨å†Œçš„æ–¹æ³•)
```

#### æ‰§è¡Œæµç¨‹

```python
# 1. FlowExecutor.run()
result = flow_executor.run(auto_info, manager)

# 2. PrefectEngine åˆ›å»º Flow
flow = prefect.flow(
    name=pipeline_name,
    retries=2,           # å¤±è´¥é‡è¯• 2 æ¬¡
    retry_delay_seconds=5
)(orchestrator_pipeline_flow)

# 3. PrefectEngine æ‰§è¡Œï¼ˆå†…éƒ¨è°ƒç”¨ KedroEngineï¼‰
result = flow(kedro_engine, pipeline_name, parameters)

# 4. KedroEngine æ‰§è¡ŒèŠ‚ç‚¹
for node in pipeline.nodes:
    # ç¼“å­˜åˆ¤æ–­
    if cache_hit:
        logger.info("ç¼“å­˜å‘½ä¸­ï¼Œè·³è¿‡æ‰§è¡Œ")
        continue

    # æ‰§è¡ŒèŠ‚ç‚¹
    result = node.run(inputs)

    # ä¿å­˜åˆ° catalog
    catalog.save(output_name, result)

# 5. MethodHandle.execute() è°ƒç”¨å®é™…æ–¹æ³•
def execute_node(*args, **kwargs):
    for method_handle in method_handles:
        # è§£æå¼•æ“ï¼ˆauto æ¨¡å¼ï¼‰
        engine = method_handle.resolve(orchestrator)

        # è°ƒç”¨ orchestrator
        result = orchestrator.execute(
            component=component,
            method=method_name,
            *resolved_args,
            **resolved_kwargs
        )
    return result
```

---

### 5ï¸âƒ£ ç¼“å­˜æœºåˆ¶ï¼ˆKedroEngineï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šå¦‚æœè¾“å…¥å’Œæ–¹æ³•æ²¡å˜ï¼Œç›´æ¥å¤ç”¨ä¹‹å‰çš„è¾“å‡ºã€‚

**ç¼“å­˜ç­¾åè®¡ç®—**ï¼š

```python
# èŠ‚ç‚¹ç­¾å = æ–¹æ³•é“¾ + å‚æ•° + ä¸Šæ¸¸è¾“å‡ºæŒ‡çº¹
signature = hash([
    "get_data",                    # æ–¹æ³•å
    "datahub::tushare::get_data",  # æ–¹æ³•å®ç°ï¼ˆå¼•æ“:ç‰ˆæœ¬:ä¼˜å…ˆçº§ï¼‰
    {"stock_code": "000001.SZ"},   # å‚æ•°
    "upstream_data:abc123"         # ä¸Šæ¸¸æ•°æ®æŒ‡çº¹
])
```

**ç¼“å­˜åˆ¤æ–­**ï¼š

```python
# 1. è®¡ç®—å½“å‰ç­¾å
new_signature = compute_signature(methods, params, upstream_data)

# 2. å¯¹æ¯”ä¸Šæ¬¡ç­¾å
old_signature = cache.get(step_name)

# 3. åˆ¤æ–­
if new_signature == old_signature and output_exists:
    logger.info("âœ… ç¼“å­˜å‘½ä¸­ï¼Œè·³è¿‡æ‰§è¡Œ")
    return cached_output
else:
    logger.info("âŒ ç¼“å­˜å¤±æ•ˆï¼Œé‡æ–°æ‰§è¡Œ")
    result = execute_node()
    cache.save(step_name, new_signature)
```

**ç¼“å­˜å¤±æ•ˆåŸå› **ï¼š
- âœ… è¾“å…¥æ•°æ®å˜åŒ–ï¼ˆä¸Šæ¸¸è¾“å‡ºæŒ‡çº¹å˜åŒ–ï¼‰
- âœ… å‚æ•°å˜åŒ–ï¼ˆ`stock_code` ä» "000001" æ”¹ä¸º "000002"ï¼‰
- âœ… æ–¹æ³•å®ç°å˜åŒ–ï¼ˆä» tushare v1.0 å‡çº§åˆ° v2.0ï¼‰
- âœ… æ–¹æ³•é“¾å˜åŒ–ï¼ˆä» `[get_data]` æ”¹ä¸º `[get_data, filter_data]`ï¼‰

---

### 6ï¸âƒ£ ç»“æœç»„è£…ï¼ˆResultAssemblerï¼‰

**èŒè´£**ï¼šæ±‡æ€»æ‰§è¡Œç»“æœã€è§£æå¼•ç”¨ã€æ ¼å¼åŒ–è¾“å‡º

```python
# ResultAssembler.assemble()
result = {
    "status": "success",              # æ‰§è¡ŒçŠ¶æ€
    "duration": "5.23s",              # æ‰§è¡Œæ—¶é•¿
    "nodes_run": 3,                   # æ‰§è¡ŒèŠ‚ç‚¹æ•°
    "execution_order": ["step1", "step2", "step3"],
    "outputs": {
        "step1": {"raw_data": DataFrame(...)},
        "step2": {"clean_data": DataFrame(...)},
        "step3": {"result": {...}}
    },
    "cache_stats": {
        "hits": 1,                    # ç¼“å­˜å‘½ä¸­æ•°
        "misses": 2,                  # ç¼“å­˜æœªå‘½ä¸­æ•°
        "saved_time": "2.1s"          # èŠ‚çœæ—¶é—´
    }
}
```

---

## ğŸ§© æ ¸å¿ƒç»„ä»¶è¯¦è§£

### ExecuteManagerï¼ˆä¸»ç®¡ç†å™¨ï¼‰

**èŒè´£**ï¼šåè°ƒæ‰€æœ‰æœåŠ¡ï¼Œæä¾›ç»Ÿä¸€å…¥å£

**å…³é”®æ–¹æ³•**ï¼š
```python
class ExecuteManager:
    def __init__(self, config_path, orchestrator):
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
        self.ctx = PipelineContext()

        # åˆå§‹åŒ–æœåŠ¡å±‚
        self._config_service = ConfigService(self.ctx, self.logger)
        self._flow_executor = FlowExecutor(self.ctx, ...)
        self._result_assembler = ResultAssembler(self.ctx, ...)

    def run(self, config_path=None, **runtime_params):
        """æ‰§è¡Œ Pipeline"""
        # 1. åŠ è½½é…ç½®
        config = self._config_service.load_config(config_path)

        # 2. æ„å»ºèŠ‚ç‚¹
        auto_info = self._config_service.build_auto_nodes(...)

        # 3. æ‰§è¡Œæµç¨‹
        result = self._flow_executor.run(auto_info, self)

        # 4. è¿”å›ç»“æœ
        return result
```

---

### PipelineContextï¼ˆå…±äº«çŠ¶æ€ï¼‰

**èŒè´£**ï¼šæ‰€æœ‰æœåŠ¡å…±äº«çš„çŠ¶æ€å®¹å™¨ï¼ˆé¿å…ä¼ é€’å¤§é‡å‚æ•°ï¼‰

**æ•°æ®ç»“æ„**ï¼š
```python
@dataclass
class PipelineContext:
    config: Dict[str, Any]              # é…ç½®
    steps: Dict[str, Any]               # æ­¥éª¤å®šä¹‰
    execution_order: List[str]          # æ‰§è¡Œé¡ºåº
    reference_values: Dict[str, Any]    # å¼•ç”¨å€¼ç¼“å­˜
    global_registry: Dict[str, Any]     # å…¨å±€æ³¨å†Œè¡¨
    reference_to_hash: Dict[str, str]   # å¼•ç”¨å“ˆå¸Œæ˜ å°„
```

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
# æ‰€æœ‰æœåŠ¡å…±äº«åŒä¸€ä¸ª context
ctx = PipelineContext()

config_service = ConfigService(ctx, logger)
flow_executor = FlowExecutor(ctx, ...)
result_assembler = ResultAssembler(ctx, ...)

# æœåŠ¡é—´é€šè¿‡ context å…±äº«æ•°æ®
config_service.load_config(path)       # å†™å…¥ ctx.config
flow_executor.run(...)                 # è¯»å– ctx.config
```

---

### MethodHandleï¼ˆæ–¹æ³•å¥æŸ„ï¼‰

**èŒè´£**ï¼šå»¶è¿Ÿç»‘å®š orchestrator æ–¹æ³•

**é—®é¢˜èƒŒæ™¯**ï¼š
```python
# âŒ å¾ªç¯ä¾èµ–é—®é¢˜
# ExecuteManager ä¾èµ– Orchestrator
# Orchestrator åˆå§‹åŒ–éœ€è¦æ—¶é—´ï¼ˆè‡ªåŠ¨å‘ç°æ–¹æ³•ï¼‰
# ConfigService åœ¨è§£ææ—¶æ— æ³•ç›´æ¥è°ƒç”¨ orchestrator

# âœ… è§£å†³æ–¹æ¡ˆï¼šMethodHandle
# è§£ææ—¶ï¼šåªè®°å½•æ–¹æ³•ä¿¡æ¯ï¼ˆcomponent, methodï¼‰
# æ‰§è¡Œæ—¶ï¼šæ‰çœŸæ­£è°ƒç”¨ orchestrator
```

**å·¥ä½œåŸç†**ï¼š
```python
# 1. åˆ›å»ºï¼ˆè§£æé˜¶æ®µï¼‰
handle = create_method_handle(
    component="datahub",
    method="get_data",
    prefer="auto"
)

# 2. æ‰§è¡Œï¼ˆè¿è¡Œé˜¶æ®µï¼‰
result = handle.execute(orchestrator, stock_code="000001.SZ")

# å†…éƒ¨å®ç°
class MethodHandle:
    def execute(self, orchestrator, *args, **kwargs):
        # åŠ¨æ€è°ƒç”¨ orchestrator
        return orchestrator.execute(
            self.component,
            self.method,
            *args,
            **kwargs
        )
```

---

### KedroEngineï¼ˆæ‰§è¡Œå¼•æ“ï¼‰

**èŒè´£**ï¼š
- åˆ›å»º Kedro èŠ‚ç‚¹
- ç®¡ç†æ•°æ®ç›®å½•ï¼ˆDataCatalogï¼‰
- ç¼“å­˜ç®¡ç†ï¼ˆç­¾åè®¡ç®—ã€åˆ¤æ–­ã€æŒä¹…åŒ–ï¼‰
- æ‰§è¡ŒèŠ‚ç‚¹

**å…³é”®æ–¹æ³•**ï¼š
```python
class KedroEngine:
    def create_pipeline(self, pipeline_name, config):
        """åˆ›å»º Kedro Pipeline"""
        nodes = [self._create_kedro_node(node_config)
                 for node_config in config.nodes]
        return Pipeline(nodes)

    def _create_kedro_node(self, node_config):
        """åˆ›å»ºå•ä¸ªèŠ‚ç‚¹"""
        def execute_node(*args, **kwargs):
            # 1. ç¼“å­˜åˆ¤æ–­
            # 2. æ‰§è¡Œæ–¹æ³•ï¼ˆé€šè¿‡ MethodHandleï¼‰
            # 3. ä¿å­˜è¾“å‡º
            # 4. æ›´æ–°ç¼“å­˜

        return Node(
            func=execute_node,
            inputs=[...],
            outputs=[...],
            name=node_config.name
        )

    def run(self, pipeline_name, parameters):
        """æ‰§è¡Œ Pipeline"""
        runner = SequentialRunner()
        return runner.run(self.pipelines[pipeline_name], self.data_catalog)
```

---

### PrefectEngineï¼ˆæµç¨‹å¼•æ“ï¼‰

**èŒè´£**ï¼š
- å°è£… Kedro Pipeline ä¸º Prefect Flow
- æä¾›å¤±è´¥é‡è¯•
- è½¯å¤±è´¥å¤„ç†ï¼ˆæŸäº›æ­¥éª¤å¤±è´¥ä¸å½±å“å…¶ä»–æ­¥éª¤ï¼‰

**å·¥ä½œåŸç†**ï¼š
```python
# 1. å®šä¹‰ Flow å‡½æ•°
@flow(name="pipeline", retries=2)
def orchestrator_pipeline_flow(kedro_engine, pipeline_name, params):
    return kedro_engine.run(pipeline_name, params)

# 2. æ‰§è¡Œ Flow
flow = orchestrator_pipeline_flow
result = flow(kedro_engine, "my_pipeline", {...})
```

---

## ğŸ“Š å®Œæ•´æ‰§è¡Œæµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ç”¨æˆ·è°ƒç”¨                                                 â”‚
â”‚    manager = ExecuteManager("pipeline.yaml")               â”‚
â”‚    result = manager.run()                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ConfigService.load_config()                             â”‚
â”‚    - åŠ è½½ YAML                                             â”‚
â”‚    - è§£æ steps                                            â”‚
â”‚    - æ‹“æ‰‘æ’åº â†’ execution_order                            â”‚
â”‚    - å†™å…¥ ctx.config, ctx.steps, ctx.execution_order      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ConfigService.build_auto_nodes()                        â”‚
â”‚    - ä¸ºæ¯ä¸ª step åˆ›å»º MethodHandle                         â”‚
â”‚    - æ„å»º Kedro èŠ‚ç‚¹é…ç½®                                   â”‚
â”‚    - è¿”å› auto_info                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. FlowExecutor.run()                                      â”‚
â”‚    - åˆ›å»º PrefectEngine                                    â”‚
â”‚    - åˆ›å»º KedroEngine                                      â”‚
â”‚    - æ‰§è¡Œ Prefect Flow                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. PrefectEngine.run_pipeline()                            â”‚
â”‚    - å®šä¹‰ Flowï¼ˆå¸¦é‡è¯•ï¼‰                                   â”‚
â”‚    - è°ƒç”¨ KedroEngine.run()                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. KedroEngine.run()                                       â”‚
â”‚    - æŒ‰ execution_order æ‰§è¡ŒèŠ‚ç‚¹                           â”‚
â”‚    - æ¯ä¸ªèŠ‚ç‚¹ï¼šç¼“å­˜åˆ¤æ–­ â†’ æ‰§è¡Œ â†’ ä¿å­˜è¾“å‡º                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. MethodHandle.execute()                                  â”‚
â”‚    - è§£æå¼•æ“ï¼ˆauto æ¨¡å¼ï¼‰                                 â”‚
â”‚    - è°ƒç”¨ orchestrator.execute()                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Orchestrator.execute()                                  â”‚
â”‚    - ä» Registry æŸ¥æ‰¾æ–¹æ³•                                  â”‚
â”‚    - ä½¿ç”¨ Strategy é€‰æ‹©å®ç°                                â”‚
â”‚    - æ‰§è¡Œæ–¹æ³•ï¼ˆå¦‚ tushare.get_dataï¼‰                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. è¿”å›ç»“æœ                                                 â”‚
â”‚    - ç»„è£…ç»“æœï¼ˆResultAssemblerï¼‰                           â”‚
â”‚    - è¿”å›ç»™ç”¨æˆ·                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ æ–°æ‰‹ä¸Šæ‰‹æŒ‡å—

### åœºæ™¯ 1ï¼šåˆ›å»ºç®€å• Pipeline

```yaml
# my_pipeline.yaml
pipeline:
  name: simple_pipeline

  steps:
    step1:
      component: datahub
      methods: [get_data]
      parameters:
        stock_code: "000001.SZ"
      outputs:
        - name: data
          type: dataset
```

```python
# æ‰§è¡Œ
from pipeline.core.execute_manager import ExecuteManager

manager = ExecuteManager(config_path="my_pipeline.yaml")
result = manager.run()
print(result["outputs"]["step1"]["data"])
```

---

### åœºæ™¯ 2ï¼šæ­¥éª¤é—´æ•°æ®ä¼ é€’

```yaml
steps:
  step1:
    component: datahub
    methods: [get_data]
    parameters:
      stock_code: "000001.SZ"
    outputs:
      - name: raw_data
        type: dataset

  step2:
    component: data_engines
    methods: [clean_data]
    parameters:
      data: "steps.step1.outputs.parameters.raw_data"  # å¼•ç”¨ step1 è¾“å‡º
    outputs:
      - name: clean_data
        type: dataset
```

---

### åœºæ™¯ 3ï¼šæ–¹æ³•é“¾ï¼ˆé“¾å¼è°ƒç”¨ï¼‰

```yaml
step1:
  component: data_engines
  methods:
    - load_data      # å…ˆæ‰§è¡Œ
    - filter_data    # ç„¶åæ‰§è¡Œï¼ˆè¾“å…¥æ˜¯ load_data çš„è¾“å‡ºï¼‰
    - transform_data # æœ€åæ‰§è¡Œï¼ˆè¾“å…¥æ˜¯ filter_data çš„è¾“å‡ºï¼‰
  parameters:
    file: "data.csv"
  outputs:
    - name: result
      type: dataset
```

---

### åœºæ™¯ 4ï¼šè¿è¡Œæ—¶å‚æ•°è¦†ç›–

```python
# é…ç½®æ–‡ä»¶å®šä¹‰é»˜è®¤å‚æ•°
# parameters:
#   stock_code: "000001.SZ"

# è¿è¡Œæ—¶è¦†ç›–
manager = ExecuteManager(config_path="my_pipeline.yaml")
result = manager.run(stock_code="000002.SZ")  # è¿è¡Œæ—¶è¦†ç›–
```

---

### åœºæ™¯ 5ï¼šæŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡

```python
result = manager.run()

# æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
cache_stats = result["cache_stats"]
print(f"ç¼“å­˜å‘½ä¸­: {cache_stats['hits']}")
print(f"ç¼“å­˜æœªå‘½ä¸­: {cache_stats['misses']}")
print(f"èŠ‚çœæ—¶é—´: {cache_stats['saved_time']}")
```

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: Pipeline å’Œ Orchestrator æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

| ç»´åº¦ | Orchestrator | Pipeline |
|------|--------------|----------|
| **èŒè´£** | æ–¹æ³•æ³¨å†Œä¸è°ƒç”¨ | å·¥ä½œæµç¼–æ’ |
| **ç²’åº¦** | å•ä¸ªæ–¹æ³• | å¤šä¸ªæ–¹æ³•çš„ç»„åˆ |
| **ä½¿ç”¨åœºæ™¯** | ç®€å•è°ƒç”¨ | å¤æ‚æµæ°´çº¿ |
| **ä¾èµ–å…³ç³»** | æ— ï¼ˆç‹¬ç«‹è°ƒç”¨ï¼‰ | æœ‰ï¼ˆæ­¥éª¤é—´ä¾èµ–ï¼‰ |
| **ç¼“å­˜** | æ—  | æœ‰ï¼ˆè‡ªåŠ¨ç¼“å­˜ï¼‰ |

**ç±»æ¯”**ï¼š
- **Orchestrator**ï¼šå‡½æ•°åº“ï¼ˆæä¾›å‡½æ•°ï¼‰
- **Pipeline**ï¼šè„šæœ¬ç¼–æ’ï¼ˆè°ƒç”¨å¤šä¸ªå‡½æ•°ï¼Œå¤„ç†ä¾èµ–ï¼‰

---

### Q2: ä¸ºä»€ä¹ˆéœ€è¦ MethodHandleï¼Ÿ

**é—®é¢˜**ï¼š
```python
# ExecuteManager éœ€è¦åœ¨åˆå§‹åŒ–æ—¶æ„å»ºèŠ‚ç‚¹
# ä½†æ­¤æ—¶ orchestrator è¿˜æ²¡åŠ è½½å®Œæ‰€æœ‰æ–¹æ³•ï¼ˆauto_discoverï¼‰
# ç›´æ¥è°ƒç”¨ä¼šå¤±è´¥
```

**è§£å†³**ï¼š
```python
# MethodHandle å®ç°"å»¶è¿Ÿç»‘å®š"
# é…ç½®è§£ææ—¶ï¼šåªè®°å½• (component, method)
# æ‰§è¡Œæ—¶ï¼šæ‰è°ƒç”¨ orchestrator.execute()
```

---

### Q3: ç¼“å­˜ä»€ä¹ˆæ—¶å€™ä¼šå¤±æ•ˆï¼Ÿ

ç¼“å­˜åŸºäº**ç­¾ååŒ¹é…**ï¼Œä»¥ä¸‹æƒ…å†µä¼šå¤±æ•ˆï¼š

1. **è¾“å…¥æ•°æ®å˜åŒ–**
   ```yaml
   parameters:
     stock_code: "000001.SZ"  # æ”¹ä¸º "000002.SZ" ä¼šå¤±æ•ˆ
   ```

2. **ä¸Šæ¸¸è¾“å‡ºå˜åŒ–**
   ```yaml
   parameters:
     data: "steps.step1.outputs.parameters.raw_data"
     # step1 é‡æ–°æ‰§è¡Œï¼Œè¾“å‡ºå˜åŒ–ï¼Œstep2 ç¼“å­˜å¤±æ•ˆ
   ```

3. **æ–¹æ³•å®ç°å˜åŒ–**
   ```python
   # tushare.get_data ä» v1.0 å‡çº§åˆ° v2.0
   # ç­¾åä¸­åŒ…å«ç‰ˆæœ¬ä¿¡æ¯ï¼Œä¼šå¯¼è‡´ç¼“å­˜å¤±æ•ˆ
   ```

4. **æ–¹æ³•é“¾å˜åŒ–**
   ```yaml
   methods: [get_data]         # æ”¹ä¸º [get_data, filter_data]
   # æ–¹æ³•åˆ—è¡¨å˜åŒ–ï¼Œç¼“å­˜å¤±æ•ˆ
   ```

---

### Q4: å¦‚ä½•è°ƒè¯• Pipeline æ‰§è¡Œï¼Ÿ

```python
# 1. å¯ç”¨ DEBUG æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# 2. æŸ¥çœ‹æ‰§è¡Œé¡ºåº
result = manager.run()
print(result["execution_order"])  # ['step1', 'step2', 'step3']

# 3. æŸ¥çœ‹æ¯ä¸ªæ­¥éª¤çš„è¾“å‡º
for step_name, outputs in result["outputs"].items():
    print(f"{step_name}: {outputs}")

# 4. æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
print(result["cache_stats"])
```

---

### Q5: å¦‚ä½•ç¦ç”¨ç¼“å­˜ï¼Ÿ

```python
# æ–¹æ³• 1ï¼šåˆ é™¤ç¼“å­˜æ–‡ä»¶
import os
if os.path.exists(".pipeline_cache.db"):
    os.remove(".pipeline_cache.db")

# æ–¹æ³• 2ï¼šä¿®æ”¹ KedroEngine ä»£ç ï¼ˆä¸´æ—¶ï¼‰
# åœ¨ _create_kedro_node ä¸­å¼ºåˆ¶ cache_hit = False
```

---

## ğŸ“ æ€»ç»“

| æ¦‚å¿µ | ä½œç”¨ | ç±»æ¯” |
|------|------|------|
| **Pipeline** | å·¥ä½œæµç¼–æ’å¼•æ“ | æµæ°´çº¿ |
| **ExecuteManager** | ä¸»ç®¡ç†å™¨ | å·¥å‚è½¦é—´ä¸»ç®¡ |
| **ConfigService** | é…ç½®è§£æ | å›¾çº¸è§£è¯»å‘˜ |
| **FlowExecutor** | æµç¨‹æ‰§è¡Œ | æµæ°´çº¿å¯åŠ¨å™¨ |
| **KedroEngine** | èŠ‚ç‚¹æ‰§è¡Œ | å·¥ä½æ“ä½œå‘˜ |
| **MethodHandle** | å»¶è¿Ÿç»‘å®š | é¢„çº¦å•ï¼ˆæ‰§è¡Œæ—¶æ‰çœŸæ­£è°ƒç”¨ï¼‰ |
| **PipelineContext** | å…±äº«çŠ¶æ€ | å…¬å‘Šæ¿ï¼ˆæ‰€æœ‰äººå…±äº«ä¿¡æ¯ï¼‰ |
| **ç¼“å­˜** | è·³è¿‡é‡å¤è®¡ç®— | æˆå“ä»“åº“ï¼ˆç›¸åŒè¾“å…¥ç›´æ¥å–è´§ï¼‰ |

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š
- âœ… **è‡ªåŠ¨ä¾èµ–ç®¡ç†**ï¼šé€šè¿‡å¼•ç”¨è‡ªåŠ¨æ£€æµ‹ä¾èµ–å…³ç³»
- âœ… **æ™ºèƒ½ç¼“å­˜**ï¼šç›¸åŒè¾“å…¥è‡ªåŠ¨å¤ç”¨ç»“æœï¼ŒåŠ é€Ÿæ‰§è¡Œ
- âœ… **å¤±è´¥é‡è¯•**ï¼šPrefect æä¾›è‡ªåŠ¨é‡è¯•æœºåˆ¶
- âœ… **æ–¹æ³•é“¾æ”¯æŒ**ï¼šä¸€ä¸ªæ­¥éª¤å¯ä»¥é“¾å¼è°ƒç”¨å¤šä¸ªæ–¹æ³•
- âœ… **è¿è¡Œæ—¶å‚æ•°**ï¼šæ”¯æŒè¿è¡Œæ—¶è¦†ç›–é…ç½®å‚æ•°
- âœ… **è¡€ç¼˜è¿½è¸ª**ï¼šè®°å½•æ•°æ®æµè½¬è·¯å¾„
- âœ… **æ˜“äºè°ƒè¯•**ï¼šè¯¦ç»†çš„æ—¥å¿—å’Œæ‰§è¡Œç»Ÿè®¡

**è®¾è®¡å“²å­¦**ï¼š
- ğŸ¯ **èŒè´£åˆ†ç¦»**ï¼šæ¯ä¸ªæœåŠ¡è´Ÿè´£ä¸€ä»¶äº‹ï¼ˆå•ä¸€èŒè´£åŸåˆ™ï¼‰
- ğŸ”Œ **è§£è€¦è®¾è®¡**ï¼šæœåŠ¡é—´é€šè¿‡ Context å…±äº«çŠ¶æ€ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
- ğŸ”§ **å»¶è¿Ÿç»‘å®š**ï¼šMethodHandle è§£å†³å¾ªç¯ä¾èµ–é—®é¢˜
- ğŸ“¦ **åˆ†å±‚æ¶æ„**ï¼šé…ç½®å±‚ â†’ æœåŠ¡å±‚ â†’ å¼•æ“å±‚ â†’ æ–¹æ³•å±‚

---

**ä¸‹ä¸€æ­¥**ï¼š
- ğŸ“– é˜…è¯» [Orchestrator æ¶æ„æ–‡æ¡£](./ORCHESTRATOR_ARCHITECTURE.md) äº†è§£æ–¹æ³•æ³¨å†Œæœºåˆ¶
- ğŸ› ï¸ å°è¯•ç¼–å†™è‡ªå·±çš„ Pipeline é…ç½®æ–‡ä»¶
- ğŸ” æŸ¥çœ‹ `pipeline/configs/` ç›®å½•ä¸‹çš„ç¤ºä¾‹é…ç½®
