"""
è¶‹åŠ¿ç»„ä»¶ä¸é…ç½®è§£æ
==================

å°è£…è¡Œä¸šé˜ˆå€¼è§£æã€ä½¿ç”¨æ¬¡æ•°ç»Ÿè®¡ä»¥åŠè§„åˆ™æ‰§è¡Œå…¥å£ã€‚é€šè¿‡ `ConfigResolver`
å’Œ `trend_rule_engine` æŠŠè¡Œä¸šå·®å¼‚åŒ–é…ç½®ä¸è¶‹åŠ¿å‘é‡ç»‘å®šï¼Œä¸ºè¯„åˆ†é˜¶æ®µæä¾›
ç»Ÿä¸€çš„ä¸Šä¸‹æ–‡ã€‚
"""

from __future__ import annotations

import logging
from collections import defaultdict
from typing import Dict, List, Optional, Tuple

import pandas as pd

from .config import INDUSTRY_FILTER_CONFIGS
from .trend_models import (
    TrendContext,
    TrendEvaluationResult,
    TrendRuleConfig,
    TrendVector,
    TrendThresholds,
)
from .trend_rules import trend_rule_engine


class ConfigResolver:
    """Resolve per-group configuration with industry overrides and usage tracking."""

    def __init__(self, industry_configs: Dict[str, Dict]) -> None:
        self.industry_configs = industry_configs
        self._usage_counter: Dict[str, int] = defaultdict(int)

    def resolve(
        self,
        group_key: str,
        base_config: Dict,
        group_df: pd.DataFrame,
        logger: logging.Logger,
    ) -> Tuple[Dict, Optional[str]]:
        resolved = dict(base_config)
        industry: Optional[str] = None

        if resolved.get("enable_filter") and "industry" in group_df.columns and not group_df["industry"].empty:
            industry = group_df["industry"].iloc[0]
            if industry in self.industry_configs:
                resolved.update(self.industry_configs[industry])
                self._usage_counter[industry] += 1
                logger.debug(
                    "%s(%s): ä½¿ç”¨è¡Œä¸šä¸“å±å‚æ•° min=%s",
                    group_key,
                    industry,
                    resolved.get("min_latest_value"),
                )

        return resolved, industry

    def usage_stats(self) -> Dict[str, int]:
        return dict(self._usage_counter)


class TrendRuleEvaluator:
    """Encapsulate rule-engine based filtering and scoring."""

    def __init__(self, logger: logging.Logger) -> None:
        self.logger = logger

    def evaluate(
        self,
        group_key: str,
        metric_name: str,
        current_config: Dict,
        trend_vector: TrendVector,
    ) -> TrendEvaluationResult:
        rule_config = TrendRuleConfig.from_dict(current_config)
        thresholds = rule_config.thresholds

        if trend_vector.is_cyclical and trend_vector.current_phase == "trough":
            thresholds = TrendThresholds(
                min_latest_value=thresholds.min_latest_value,
                severe_decline=thresholds.severe_decline * 1.5,
                mild_decline=thresholds.mild_decline,
                latest_threshold=thresholds.latest_threshold,
                trend_significance=thresholds.trend_significance,
            )
            self.logger.debug(
                "ğŸ”„ å‘¨æœŸæ€§è°ƒæ•´: %s - åº•éƒ¨é˜¶æ®µ,æ”¾å®½è¡°é€€é˜ˆå€¼è‡³%.3f",
                group_key,
                thresholds.severe_decline,
            )

        params = rule_config.parameters

        trend_context = TrendContext.from_vector(group_key, metric_name, trend_vector)

        outcome = trend_rule_engine.run(trend_context, params, thresholds, self.logger)

        if not outcome.passes:
            return TrendEvaluationResult(
                passes=False,
                elimination_reason=outcome.elimination_reason,
                penalty=outcome.penalty,
                penalty_details=outcome.penalty_details,
                bonus_details=outcome.bonus_details,
                trend_score=0.0,
                auxiliary_notes=outcome.auxiliary_notes,
            )

        penalty = outcome.penalty
        penalty_details = outcome.penalty_details
        bonus_details = outcome.bonus_details

        max_penalty_threshold = float(params.max_penalty)
        if penalty >= max_penalty_threshold:
            reason = f"ç´¯ç§¯ç½šåˆ†{penalty:.1f}>={max_penalty_threshold}é˜ˆå€¼"
            self.logger.info("âŒ ã€ç´¯ç§¯æ·˜æ±°ã€‘%s: æ€»ç½šåˆ†%.1f", group_key, penalty)
            if penalty_details:
                self.logger.info("   æ‰£åˆ†é¡¹: %s", "; ".join(penalty_details))
            if bonus_details:
                self.logger.info("   åŠ åˆ†é¡¹: %s", "; ".join(bonus_details))
            return TrendEvaluationResult(
                passes=False,
                elimination_reason=reason,
                penalty=penalty,
                penalty_details=penalty_details,
                bonus_details=bonus_details,
                trend_score=0.0,
                auxiliary_notes=outcome.auxiliary_notes,
            )

        if penalty > 0 or bonus_details:
            self.logger.debug("âœ… ã€é€šè¿‡ã€‘%s: ç½šåˆ†%.1f", group_key, penalty)
            if penalty_details:
                self.logger.debug("   æ‰£åˆ†é¡¹: %s", "; ".join(penalty_details))
            if bonus_details:
                self.logger.debug("   åŠ åˆ†é¡¹: %s", "; ".join(bonus_details))

        if outcome.auxiliary_notes:
            self.logger.debug("â„¹ï¸ ã€ROIICè¾…åŠ©ã€‘%s: %s", group_key, "; ".join(outcome.auxiliary_notes))

        if max_penalty_threshold <= 0:
            trend_score = 0.0
        else:
            trend_score = 100.0 - (penalty / max_penalty_threshold) * 100.0
            trend_score = max(0.0, min(100.0, round(trend_score, 2)))

        return TrendEvaluationResult(
            passes=True,
            elimination_reason="",
            penalty=penalty,
            penalty_details=penalty_details,
            bonus_details=bonus_details,
            trend_score=trend_score,
            auxiliary_notes=outcome.auxiliary_notes,
        )


class TrendResultCollector:
    """Collect per-group trend outputs and provide summary helpers."""

    def __init__(self) -> None:
        self._rows: List[Dict] = []

    def add(self, row: Dict) -> None:
        self._rows.append(row)

    def to_dataframe(self) -> pd.DataFrame:
        return pd.DataFrame(self._rows)
