"""
ç»¼åˆè¶‹åŠ¿åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ (Comprehensive Trend Report Generator)
===========================================================

è¿™æ˜¯ä¸€ä¸ªä¸“ä¸šçº§çš„é‡åŒ–åŸºæœ¬é¢åˆ†ææŠ¥å‘Šç”Ÿæˆæ¡†æ¶ã€‚
å®ƒé‡‡ç”¨"å¤šå› å­è¯„åˆ†æ¨¡å‹ (Multi-Factor Scoring Model)"ï¼Œç»“åˆ"è¡Œä¸šç›¸å¯¹æ’å (Industry Relative Ranking)"ï¼Œ
å¯¹å…¨å¸‚åœºè‚¡ç¥¨è¿›è¡Œæ·±åº¦æ‰«æå’Œåˆ†å±‚ç­›é€‰ã€‚

æ ¸å¿ƒæ–¹æ³•è®ºï¼š
1.  **GARPç­–ç•¥ (Growth at a Reasonable Price)**: å¯»æ‰¾é«˜è´¨é‡æˆé•¿è‚¡ã€‚
2.  **Qualityç­–ç•¥ (Quality Factor)**: å¯»æ‰¾é«˜ROEã€é«˜ROICã€é«˜å£å’çš„è¡Œä¸šé¾™å¤´ã€‚
3.  **Turnaroundç­–ç•¥ (Reversal Factor)**: å¯»æ‰¾åŸºæœ¬é¢å‡ºç°æ‹ç‚¹çš„å›°å¢ƒåè½¬è‚¡ã€‚

è¯„åˆ†ä½“ç³» (0-100åˆ†):
-   **æˆé•¿å› å­ (Growth Factor)**: è¥æ”¶CAGRæ’å + åˆ©æ¶¦CAGRæ’å + ä¸šç»©åŠ é€Ÿåº¦
-   **è´¨é‡å› å­ (Quality Factor)**: ROEæ’å + ROICæ’å + æ¯›åˆ©ç‡æ’å + åˆ©æ¶¦ç¨³å®šæ€§
-   **å®‰å…¨å› å­ (Safety Factor)**: ç»è¥ç°é‡‘æµè¦†ç›–ç‡ + ç°é‡‘æµè¶‹åŠ¿

è§„æ¨¡åˆ†ç±»æ ‡å‡† (æŒ‰æŠ•å…¥èµ„æœ¬):
-   **å¾®å‹ (Micro)**: < 10äº¿ - æµåŠ¨æ€§å·®ï¼Œé£é™©æé«˜
-   **å°å‹ (Small)**: 10-50äº¿ - æˆé•¿ç©ºé—´å¤§ï¼Œä½†æ³¢åŠ¨å‰§çƒˆ
-   **ä¸­å‹ (Mid)**: 50-200äº¿ - ç›¸å¯¹ç¨³å¥ï¼Œæœºæ„å…³æ³¨åº¦æå‡
-   **å¤§å‹ (Large)**: 200-1000äº¿ - è¡Œä¸šé¾™å¤´ï¼ŒæµåŠ¨æ€§å¥½
-   **è¶…å¤§å‹ (Mega)**: > 1000äº¿ - è“ç­¹ç™½é©¬ï¼Œç¨³å®šæ€§æœ€é«˜

ä½œè€…: AStock Analysis System
æ—¥æœŸ: 2025-12-06
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime


# è§„æ¨¡åˆ†ç±»æ ‡ç­¾ (ç”¨äºå±•ç¤ºï¼Œè§„æ¨¡åˆ†ç±»å·²åœ¨æ•°æ®å±‚å®Œæˆ)
SIZE_LABELS = {
    'micro': 'ğŸ”¹å¾®å‹',
    'small': 'ğŸ”¸å°å‹',
    'mid': 'ğŸ”¶ä¸­å‹',
    'large': 'ğŸ”·å¤§å‹',
    'mega': 'ğŸ’è¶…å¤§'
}

SIZE_RISKS = {
    'micro': 'âš ï¸é«˜é£é™©',
    'small': 'âš¡ä¸­é«˜é£é™©',
    'mid': 'âœ…ç¨³å¥',
    'large': 'âœ…ä½é£é™©',
    'mega': 'âœ…æœ€ç¨³å¥'
}


class ComprehensiveReportGenerator:
    def __init__(self, data_dir: str = "data/filter_middle"):
        self.data_dir = Path(data_dir)
        self.metrics_config = {
            "revenue": {"file": "revenue_trend_analysis.csv", "prefix": "total_revenue_ps", "name": "è¥æ”¶"},
            "profit": {"file": "profit_trend_analysis.csv", "prefix": "eps", "name": "åˆ©æ¶¦"},
            "roe": {"file": "roe_trend_analysis.csv", "prefix": "roe", "name": "ROE"},
            "ocf": {"file": "ocf_trend_analysis.csv", "prefix": "ocfps", "name": "ç»è¥ç°é‡‘æµ"},
            "gross_margin": {"file": "gross_margin_trend_analysis.csv", "prefix": "grossprofit_margin", "name": "æ¯›åˆ©ç‡"},
            "net_margin": {"file": "net_margin_trend_analysis.csv", "prefix": "netprofit_margin", "name": "å‡€åˆ©ç‡"},
            "roic": {"file": "roic_trend_analysis.csv", "prefix": "roic", "name": "ROIC"},
            "roiic": {"file": "roiic_trend_analysis.csv", "prefix": "roiic", "name": "ROIIC"},
        }
        self.df_merged = pd.DataFrame()

    def _calculate_factor_scores(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æ ¸å¿ƒå› å­å¾—åˆ† (0-100åˆ†)
        é‡‡ç”¨è¡Œä¸šå†…æ’å(Percentile)ä¸å…¨å¸‚åœºæ’åç›¸ç»“åˆçš„æ–¹å¼
        """
        df_scored = df.copy()

        # è¾…åŠ©å‡½æ•°: è®¡ç®—ç™¾åˆ†ä½æ’å (0-1)
        def get_rank(series, group_col=None):
            if group_col is not None:
                return df_scored.groupby(group_col)[series.name].rank(pct=True, ascending=True)
            return series.rank(pct=True, ascending=True)

        # --- 1. è´¨é‡å› å­ (Quality Factor) ---
        # æ ¸å¿ƒæŒ‡æ ‡: ROE, ROIC, æ¯›åˆ©ç‡
        # é€»è¾‘: è¡Œä¸šåœ°ä½(è¡Œä¸šæ’å) + ç»å¯¹ç›ˆåˆ©èƒ½åŠ›(å…¨å¸‚åœºæ’å)

        col_roe = self._get_col('roe', 'latest')
        col_roic = self._get_col('roic', 'latest')
        col_gm = self._get_col('gross_margin', 'latest')

        if col_roe in df.columns:
            df_scored['rank_roe_ind'] = get_rank(df_scored[col_roe], 'industry')
            df_scored['rank_roe_all'] = get_rank(df_scored[col_roe])
        else:
            df_scored['rank_roe_ind'] = 0
            df_scored['rank_roe_all'] = 0

        if col_roic in df.columns:
            df_scored['rank_roic_ind'] = get_rank(df_scored[col_roic], 'industry')
        else:
            df_scored['rank_roic_ind'] = 0

        if col_gm in df.columns:
            df_scored['rank_gm_ind'] = get_rank(df_scored[col_gm], 'industry')
        else:
            df_scored['rank_gm_ind'] = 0

        # è´¨é‡åˆ† = 40% ROE(è¡Œä¸š) + 20% ROE(å…¨å¸‚åœº) + 30% ROIC(è¡Œä¸š) + 10% æ¯›åˆ©ç‡(è¡Œä¸š)
        # è§£é‡Š: æ—¢è¦çœ‹æ˜¯ä¸æ˜¯è¡Œä¸šé¾™å¤´(ROE_ind)ï¼Œä¹Ÿè¦çœ‹æ˜¯ä¸æ˜¯çœŸçš„èµšé’±æœºå™¨(ROE_all)ï¼ŒROICä»£è¡¨èµ„æœ¬æ•ˆç‡
        df_scored['score_quality'] = (
            0.4 * df_scored['rank_roe_ind'] +
            0.2 * df_scored['rank_roe_all'] +
            0.3 * df_scored['rank_roic_ind'] +
            0.1 * df_scored['rank_gm_ind']
        ) * 100

        # --- 2. æˆé•¿å› å­ (Growth Factor) ---
        # æ ¸å¿ƒæŒ‡æ ‡: è¥æ”¶CAGR, åˆ©æ¶¦CAGR, è¶‹åŠ¿ç¨³å®šæ€§
        col_rev_cagr = self._get_col('revenue', 'cagr')
        col_prof_cagr = self._get_col('profit', 'cagr')

        if col_rev_cagr in df.columns:
            df_scored['rank_rev_ind'] = get_rank(df_scored[col_rev_cagr], 'industry')
        else:
            df_scored['rank_rev_ind'] = 0

        if col_prof_cagr in df.columns:
            df_scored['rank_prof_ind'] = get_rank(df_scored[col_prof_cagr], 'industry')
        else:
            df_scored['rank_prof_ind'] = 0

        # æˆé•¿åˆ† = 40% è¥æ”¶æˆé•¿(è¡Œä¸š) + 40% åˆ©æ¶¦æˆé•¿(è¡Œä¸š) + 20% ç»å¯¹å¢é€Ÿä¿®æ­£
        # ä¿®æ­£: å¦‚æœç»å¯¹å¢é€Ÿ < 0ï¼Œå¼ºåˆ¶æ‰£åˆ†
        base_growth = 0.5 * df_scored['rank_rev_ind'] + 0.5 * df_scored['rank_prof_ind']
        df_scored['score_growth'] = base_growth * 100

        # --- 3. å®‰å…¨å› å­ (Safety Factor) ---
        # æ ¸å¿ƒæŒ‡æ ‡: ç»è¥ç°é‡‘æµè¶‹åŠ¿
        col_ocf_slope = self._get_col('ocf', 'log_slope')
        if col_ocf_slope in df.columns:
            # ç®€å•çš„äºŒå…ƒé€»è¾‘: ç°é‡‘æµæ¶åŒ–ç›´æ¥ç»™ä½åˆ†
            df_scored['score_safety'] = np.where(df_scored[col_ocf_slope] > -0.05, 100, 0)
        else:
            df_scored['score_safety'] = 50 # ç¼ºå¤±å€¼ç»™ä¸­æ€§åˆ†

        return df_scored

    def load_and_merge_data(self) -> pd.DataFrame:
        """åŠ è½½å¹¶åˆå¹¶æ‰€æœ‰æŒ‡æ ‡æ•°æ®"""
        merged = None

        print(f"æ­£åœ¨åŠ è½½æ•°æ®ç›®å½•: {self.data_dir.absolute()}")

        for key, config in self.metrics_config.items():
            file_path = self.data_dir / config["file"]
            if not file_path.exists():
                print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨ {file_path}, è·³è¿‡æŒ‡æ ‡ {key}")
                continue

            try:
                df = pd.read_csv(file_path)
                # ç»Ÿä¸€åˆ—åï¼Œä¿ç•™ ts_code, name, industry ä½œä¸ºä¸»é”®
                # å…¶ä»–åˆ—åŠ ä¸Š metric å‰ç¼€ (å¦‚æœ CSV é‡Œå·²ç»æ˜¯ prefix_field æ ¼å¼ï¼Œåˆ™ä¿æŒ)
                # è¿™é‡Œå‡è®¾ CSV é‡Œçš„åˆ—åå·²ç»æ˜¯ {prefix}_{field} æ ¼å¼

                # åªéœ€è¦ä¿ç•™ ts_code, name, industry ä¸€æ¬¡
                cols_to_keep = ['ts_code', 'name', 'industry']
                cols_data = [c for c in df.columns if c not in cols_to_keep]

                if merged is None:
                    merged = df
                else:
                    merged = pd.merge(merged, df[['ts_code'] + cols_data], on='ts_code', how='outer')

            except Exception as e:
                print(f"âŒ åŠ è½½ {key} å¤±è´¥: {e}")

        # === åŠ è½½åŸå§‹æ•°æ®è·å–è§„æ¨¡åˆ†ç±»(å·²åœ¨æ•°æ®å±‚é¢„è®¡ç®—) ===
        self._load_size_data(merged)

        self.df_merged = merged
        return merged

    def _load_size_data(self, df: pd.DataFrame) -> None:
        """
        åŠ è½½è§„æ¨¡åˆ†ç±»æ•°æ®
        è§„æ¨¡åˆ†ç±»å·²åœ¨æ•°æ®å±‚(polarså¼•æ“)é¢„è®¡ç®—å¹¶å­˜å‚¨åœ¨CSVä¸­
        """
        raw_data_path = self.data_dir.parent / "polars" / "5yd_final_industry.csv"
        if raw_data_path.exists():
            try:
                df_raw = pd.read_csv(raw_data_path)
                # å–æ¯ä¸ªå…¬å¸æœ€æ–°ä¸€æœŸçš„æ•°æ®
                latest = df_raw.sort_values('end_date').groupby('ts_code').last().reset_index()

                # åŠ è½½ size_class åˆ—(æ•°æ®å±‚é¢„è®¡ç®—)
                if 'size_class' in latest.columns:
                    df['size_class'] = df['ts_code'].map(
                        latest.set_index('ts_code')['size_class']
                    )
                    # æ·»åŠ æ ‡ç­¾å’Œé£é™©ç­‰çº§
                    df['size_label'] = df['size_class'].map(SIZE_LABELS)
                    df['size_risk'] = df['size_class'].map(SIZE_RISKS)
                    print(f"âœ… å·²åŠ è½½è§„æ¨¡æ•°æ®ï¼Œè§„æ¨¡åˆ†å¸ƒ: {df['size_class'].value_counts().to_dict()}")
                else:
                    print("âš ï¸ æ•°æ®ä¸­ç¼ºå°‘ size_class åˆ—ï¼Œè¯·å…ˆè¿è¡Œ workflow/tushare_fina.yaml æ›´æ–°æ•°æ®")

                # åŒæ—¶åŠ è½½æŠ•å…¥èµ„æœ¬ç”¨äºå±•ç¤º
                if 'invest_capital' in latest.columns and 'invest_capital' not in df.columns:
                    df['invest_capital'] = df['ts_code'].map(
                        latest.set_index('ts_code')['invest_capital']
                    )
                    df['invest_capital_yi'] = df['invest_capital'] / 1e8

            except Exception as e:
                print(f"âš ï¸ åŠ è½½è§„æ¨¡æ•°æ®å¤±è´¥: {e}")

    def _get_col(self, metric_key: str, field: str) -> str:
        """è·å–ç‰¹å®šæŒ‡æ ‡çš„åˆ—å"""
        prefix = self.metrics_config[metric_key]["prefix"]
        return f"{prefix}_{field}"

    def generate_report(self, output_path: str = "data/comprehensive_analysis_report.md") -> str:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        if self.df_merged is None or self.df_merged.empty:
            self.load_and_merge_data()

        if self.df_merged is None or self.df_merged.empty:
            return "âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚"

        df = self.df_merged
        lines = []

        # === æ ‡é¢˜ ===
        lines.append(f"# AStock æ·±åº¦åŸºæœ¬é¢é‡åŒ–åˆ†ææŠ¥å‘Š")
        lines.append(f"> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"> è¦†ç›–å…¬å¸: {len(df)} å®¶")

        # æ˜¾ç¤ºè§„æ¨¡åˆ†å¸ƒæ¦‚å†µ
        if 'size_class' in df.columns:
            size_counts = df['size_class'].value_counts()
            lines.append(f"> è§„æ¨¡åˆ†å¸ƒ: è¶…å¤§å‹ {size_counts.get('mega', 0)} | å¤§å‹ {size_counts.get('large', 0)} | ä¸­å‹ {size_counts.get('mid', 0)} | å°å‹ {size_counts.get('small', 0)} | å¾®å‹ {size_counts.get('micro', 0)}")
        lines.append("")

        lines.append("> âš ï¸ **æŠ•èµ„æç¤º**: æœ¬æŠ¥å‘Šä»…å±•ç¤º**ä¸­å‹(50-200äº¿)**ã€**å¤§å‹(200-1000äº¿)**ã€**è¶…å¤§å‹(>1000äº¿)**å…¬å¸ã€‚")
        lines.append("> å°å‹å’Œå¾®å‹å…¬å¸å› æµåŠ¨æ€§å·®ã€æ³¢åŠ¨å‰§çƒˆã€ä¿¡æ¯ä¸å¯¹ç§°ç­‰é£é™©ï¼Œå·²ä»æ¨èåˆ—è¡¨ä¸­å‰”é™¤ã€‚")
        lines.append("")

        # === 1. æŒ‰è§„æ¨¡åˆ†ç±»å±•ç¤ºä¼˜è´¨å…¬å¸ ===
        lines.extend(self._section_quality_by_size(df))

        # === 2. ä¼˜è´¨ç™½é©¬ä¸æŠ¤åŸæ²³ (ä»…ä¸­å¤§å‹) ===
        lines.extend(self._section_quality_moat(df))

        # === 3. å›°å¢ƒåè½¬æœºä¼š (ä»…ä¸­å¤§å‹) ===
        lines.extend(self._section_turnaround(df))

        # === 4. äº¤å‰éªŒè¯é£é™©è­¦ç¤º (Risk Warnings) ===
        lines.extend(self._section_cross_validation_risks(df))

        # === 5. è¡Œä¸šå…¨æ™¯å›¾ (Industry Overview) ===
        lines.extend(self._section_industry_overview(df))

        # === ä¿å­˜ ===
        report_content = "\n".join(lines)
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        Path(output_path).write_text(report_content, encoding='utf-8')
        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return report_content

    def _section_quality_by_size(self, df: pd.DataFrame) -> List[str]:
        """
        æŒ‰è§„æ¨¡åˆ†ç±»å±•ç¤ºä¼˜è´¨å…¬å¸
        åªå±•ç¤ºä¸­å‹ã€å¤§å‹ã€è¶…å¤§å‹ï¼Œå¿½ç•¥å°å‹å’Œå¾®å‹
        """
        lines = ["## ğŸ† ä¼˜è´¨å…¬å¸ç²¾é€‰ (æŒ‰è§„æ¨¡åˆ†ç±»)", ""]
        lines.append("åŸºäº**å¤šå› å­è¯„åˆ†æ¨¡å‹**ï¼ŒæŒ‰å…¬å¸è§„æ¨¡åˆ†åˆ«å±•ç¤ºä¼˜è´¨æ ‡çš„ã€‚")
        lines.append("- **æˆé•¿å› å­ (30%)**: è¥æ”¶/åˆ©æ¶¦CAGR")
        lines.append("- **è´¨é‡å› å­ (40%)**: ROE/ROIC/æ¯›åˆ©ç‡")
        lines.append("- **å®‰å…¨å› å­ (30%)**: ç°é‡‘æµå¥åº·åº¦")
        lines.append("")

        # 1. è®¡ç®—å› å­å¾—åˆ†
        df_scored = self._calculate_factor_scores(df)

        # 2. ç»¼åˆè¯„åˆ†
        df_scored['composite_score'] = (
            0.4 * df_scored['score_quality'] +
            0.3 * df_scored['score_growth'] +
            0.3 * df_scored['score_safety']
        )

        # ç­›é€‰é—¨æ§›
        candidates = df_scored[
            (df_scored['composite_score'] > 60) &
            (df_scored['score_quality'] > 50) &
            (df_scored['score_safety'] > 50)
        ].copy()

        # æŒ‰è§„æ¨¡åˆ†åˆ«å±•ç¤º (è¶…å¤§å‹ -> å¤§å‹ -> ä¸­å‹)
        size_order = [
            ('mega', 'ğŸ’ è¶…å¤§å‹å…¬å¸ (æŠ•å…¥èµ„æœ¬ > 1000äº¿)', 'è“ç­¹ç™½é©¬ï¼ŒæµåŠ¨æ€§æä½³ï¼Œé€‚åˆç¨³å¥é…ç½®'),
            ('large', 'ğŸ”· å¤§å‹å…¬å¸ (æŠ•å…¥èµ„æœ¬ 200-1000äº¿)', 'è¡Œä¸šé¾™å¤´ï¼Œæœºæ„é‡ä»“ï¼Œé£é™©å¯æ§'),
            ('mid', 'ğŸ”¶ ä¸­å‹å…¬å¸ (æŠ•å…¥èµ„æœ¬ 50-200äº¿)', 'æˆé•¿æ½œåŠ›å¤§ï¼Œæœºæ„å…³æ³¨åº¦æå‡')
        ]

        for size_key, title, desc in size_order:
            if 'size_class' not in candidates.columns:
                lines.append(f"*(è§„æ¨¡æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ†ç±»å±•ç¤º)*")
                break

            size_df = candidates[candidates['size_class'] == size_key].copy()
            if size_df.empty:
                continue

            # æŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼Œå–å‰15
            top_picks = size_df.sort_values('composite_score', ascending=False).head(15)

            lines.append(f"### {title}")
            lines.append(f"> {desc}")
            lines.append("")
            lines.append("| ä»£ç  | åç§° | è¡Œä¸š | æŠ•å…¥èµ„æœ¬(äº¿) | ç»¼åˆè¯„åˆ† | æˆé•¿åˆ† | è´¨é‡åˆ† | å®‰å…¨åˆ† | æ ¸å¿ƒäº®ç‚¹ |")
            lines.append("|---|---|---|---|---|---|---|---|---|")

            for _, row in top_picks.iterrows():
                code = row['ts_code']
                name = row['name']
                ind = row['industry']
                score = row['composite_score']
                s_growth = row['score_growth']
                s_quality = row['score_quality']
                s_safety = row['score_safety']
                ic_yi = row.get('invest_capital_yi', 0)

                # ç”Ÿæˆç®€çŸ­è¯„è¯­
                highlights = []
                if row.get('rank_roe_ind', 0) > 0.8: highlights.append("è¡Œä¸šç›ˆåˆ©é¾™å¤´")
                if row.get('rank_rev_ind', 0) > 0.8: highlights.append("è¡Œä¸šé«˜æˆé•¿")
                if row.get('rank_roic_ind', 0) > 0.8: highlights.append("èµ„æœ¬æ•ˆç‡é«˜")
                if not highlights: highlights.append("ç»¼åˆä¼˜è´¨")

                lines.append(f"| {code} | {name} | {ind} | {ic_yi:.1f} | **{score:.1f}** | {s_growth:.1f} | {s_quality:.1f} | {s_safety:.1f} | {', '.join(highlights)} |")

            lines.append("")

        return lines

    def _section_quality_moat(self, df: pd.DataFrame) -> List[str]:
        """
        ç­›é€‰ä¼˜è´¨ç™½é©¬/æŠ¤åŸæ²³ä¼ä¸š (Quality Strategy)
        ä¾§é‡äºé«˜ROEã€é«˜ROICå’Œè¡Œä¸šåœ°ä½ï¼ŒæŒ‰è§„æ¨¡åˆ†ç±»å±•ç¤º
        """
        lines = ["## ğŸ° ä¼˜è´¨ç™½é©¬ä¸æŠ¤åŸæ²³ (Quality Moat)", ""]
        lines.append("ç­›é€‰æ ‡å‡†ï¼š**è´¨é‡å› å­ä¼˜å…ˆ**ï¼Œå¯»æ‰¾å…·æœ‰æ·±åšæŠ¤åŸæ²³ã€æé«˜èµ„æœ¬å›æŠ¥ç‡çš„è¡Œä¸šé¾™å¤´ã€‚")
        lines.append("- **æ ¸å¿ƒæŒ‡æ ‡**: è´¨é‡åˆ† (æƒé‡ 70%) + å®‰å…¨åˆ† (æƒé‡ 30%)")
        lines.append("- **å¿½ç•¥æŒ‡æ ‡**: çŸ­æœŸæˆé•¿é€Ÿåº¦ (å…è®¸æˆç†ŸæœŸä¼ä¸šå¢é€Ÿæ”¾ç¼“)")
        lines.append("")

        # 1. è®¡ç®—å› å­å¾—åˆ† (å¦‚æœå°šæœªè®¡ç®—)
        if 'score_quality' not in df.columns:
            df_scored = self._calculate_factor_scores(df)
        else:
            df_scored = df.copy()

        # 2. æŠ¤åŸæ²³è¯„åˆ† (Moat Score)
        df_scored['moat_score'] = 0.7 * df_scored['score_quality'] + 0.3 * df_scored['score_safety']

        # 3. ç­›é€‰é€»è¾‘: è´¨é‡åˆ†å¿…é¡»æé«˜ (>70)
        moat_base = df_scored[df_scored['score_quality'] > 70].copy()

        if moat_base.empty:
            lines.append("*(æš‚æ— ç¬¦åˆä¸¥è‹›è´¨é‡æ ‡å‡†çš„å…¬å¸)*")
            return lines

        # æŒ‰è§„æ¨¡åˆ†åˆ«å±•ç¤º (è¶…å¤§å‹ -> å¤§å‹ -> ä¸­å‹)
        size_order = [
            ('mega', 'ğŸ’ è¶…å¤§å‹ç™½é©¬ (æŠ•å…¥èµ„æœ¬ > 1000äº¿)', 'è“ç­¹ç™½é©¬ï¼ŒæŠ¤åŸæ²³æ·±åšï¼Œé•¿æœŸæŒæœ‰é¦–é€‰'),
            ('large', 'ğŸ”· å¤§å‹ç™½é©¬ (æŠ•å…¥èµ„æœ¬ 200-1000äº¿)', 'è¡Œä¸šé¾™å¤´ï¼Œç›ˆåˆ©ç¨³å®šï¼Œæœºæ„é‡ä»“'),
            ('mid', 'ğŸ”¶ ä¸­å‹ç™½é©¬ (æŠ•å…¥èµ„æœ¬ 50-200äº¿)', 'ç»†åˆ†é¾™å¤´ï¼Œé«˜ROEé«˜ROICï¼Œæˆé•¿ç©ºé—´å¤§')
        ]

        for size_key, title, desc in size_order:
            if 'size_class' not in moat_base.columns:
                lines.append(f"*(è§„æ¨¡æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ†ç±»å±•ç¤º)*")
                break

            size_df = moat_base[moat_base['size_class'] == size_key].copy()
            if size_df.empty:
                continue

            # æŒ‰æŠ¤åŸæ²³è¯„åˆ†æ’åºï¼Œå–å‰20
            top_moat = size_df.sort_values('moat_score', ascending=False).head(20)

            lines.append(f"### {title}")
            lines.append(f"> {desc}")
            lines.append("")
            lines.append("| ä»£ç  | åç§° | è¡Œä¸š | æŠ•å…¥èµ„æœ¬(äº¿) | æŠ¤åŸæ²³åˆ† | è´¨é‡åˆ† | å®‰å…¨åˆ† | æœ€æ–°ROE | æœ€æ–°ROIC |")
            lines.append("|---|---|---|---|---|---|---|---|---|")

            for _, row in top_moat.iterrows():
                code = row['ts_code']
                name = row['name']
                ind = row['industry']
                m_score = row['moat_score']
                q_score = row['score_quality']
                s_score = row['score_safety']
                ic_yi = row.get('invest_capital_yi', 0)

                roe = row.get(self._get_col('roe', 'latest'), 0)
                roic = row.get(self._get_col('roic', 'latest'), 0)

                lines.append(f"| {code} | {name} | {ind} | {ic_yi:.1f} | **{m_score:.1f}** | {q_score:.1f} | {s_score:.1f} | {roe:.1f}% | {roic:.1f}% |")

            lines.append("")

        return lines

    def _section_turnaround(self, df: pd.DataFrame) -> List[str]:
        """ç­›é€‰å›°å¢ƒåè½¬å…¬å¸ (ä»…ä¸­å¤§å‹)"""
        lines = ["## ğŸš€ å›°å¢ƒåè½¬æœºä¼š (Turnaround)", ""]
        lines.append("ç­›é€‰æ ‡å‡†ï¼š**åŸºæœ¬é¢è§¦åº•å›å‡** + **æ¯›åˆ©ç‡æ”¹å–„** + **ç°é‡‘æµè½¬æ­£** + **ä»…ä¸­å¤§å‹å…¬å¸**")
        lines.append("")

        # 1. åˆ©æ¶¦æˆ–è¥æ”¶å‡ºç°åè½¬ä¿¡å·
        prof_turnaround = df[self._get_col('profit', 'is_turnaround')] == 1
        rev_turnaround = df[self._get_col('revenue', 'is_turnaround')] == 1

        # 2. è´¨é‡ç¡®è®¤: æ¯›åˆ©ç‡ä¸èƒ½æš´è·Œ (é˜²æ­¢é™ä»·æ¸…åº“å­˜)
        gm_slope = df[self._get_col('gross_margin', 'log_slope')]
        quality_check = gm_slope > -0.02

        # 3. åªç­›é€‰ä¸­å‹åŠä»¥ä¸Šå…¬å¸
        if 'size_class' in df.columns:
            size_filter = df['size_class'].isin(['mid', 'large', 'mega'])
        else:
            size_filter = pd.Series([True] * len(df), index=df.index)

        candidates = df[(prof_turnaround | rev_turnaround) & quality_check & size_filter].copy()

        if candidates.empty:
            lines.append("*(æš‚æ— ç¬¦åˆæ ‡å‡†çš„ä¸­å¤§å‹åè½¬å…¬å¸)*")
        else:
            # æŒ‰è¿‘æœŸæ–œç‡æ’åº
            sort_col = self._get_col('profit', 'recent_3y_slope')
            if sort_col in candidates.columns:
                candidates = candidates.sort_values(sort_col, ascending=False).head(15)

            lines.append("| ä»£ç  | åç§° | è¡Œä¸š | è§„æ¨¡ | æŠ•å…¥èµ„æœ¬(äº¿) | åè½¬ç±»å‹ | è¿‘3å¹´åˆ©æ¶¦æ–œç‡ | æœ€æ–°æ¯›åˆ©ç‡ | è¯„è¯­ |")
            lines.append("|---|---|---|---|---|---|---|---|---|")

            for _, row in candidates.iterrows():
                code = row['ts_code']
                name = row['name']
                ind = row['industry']
                prof_slope = row.get(self._get_col('profit', 'recent_3y_slope'), 0)
                gm = row.get(self._get_col('gross_margin', 'latest'), 0)

                # è§„æ¨¡ä¿¡æ¯
                size_label = row.get('size_label', 'æœªçŸ¥')
                ic_yi = row.get('invest_capital_yi', 0)

                reasons = []
                if row.get(self._get_col('profit', 'is_turnaround')): reasons.append(row.get(self._get_col('profit', 'strategy_reasons'), 'åˆ©æ¶¦åè½¬'))

                lines.append(f"| {code} | {name} | {ind} | {size_label} | {ic_yi:.1f} | {'åˆ©æ¶¦/è¥æ”¶åè½¬'} | {prof_slope:.2f} | {gm:.1f}% | {'; '.join(reasons)[:30]}... |")

        lines.append("")
        return lines

    def _section_cross_validation_risks(self, df: pd.DataFrame) -> List[str]:
        """äº¤å‰éªŒè¯é£é™©åˆ†æ"""
        lines = ["## âš ï¸ äº¤å‰éªŒè¯é£é™©è­¦ç¤º (Risk Warnings)", ""]
        lines.append("ä»¥ä¸‹å…¬å¸å­˜åœ¨**è´¢åŠ¡æŒ‡æ ‡èƒŒç¦»**ï¼Œå»ºè®®è°¨æ…å¯¹å¾…ï¼š")
        lines.append("")

        risky_list = []

        # 1. çº¸é¢å¯Œè´µ: åˆ©æ¶¦é«˜å¢ vs ç°é‡‘æµæ¶åŒ–
        prof_slope = df[self._get_col('profit', 'log_slope')]
        ocf_slope = df[self._get_col('ocf', 'log_slope')]

        mask_paper_wealth = (prof_slope > 0.15) & (ocf_slope < -0.05)
        paper_wealth = df[mask_paper_wealth].copy()
        for _, row in paper_wealth.iterrows():
            risky_list.append({
                "code": row['ts_code'], "name": row['name'], "type": "çº¸é¢å¯Œè´µ",
                "desc": f"åˆ©æ¶¦å¢é€Ÿ {row[self._get_col('profit', 'log_slope')]:.1%} vs OCFå¢é€Ÿ {row[self._get_col('ocf', 'log_slope')]:.1%}"
            })

        # 2. çƒ§é’±æ‰©å¼ : è¥æ”¶é«˜å¢ vs ROE ä½è¿·
        rev_slope = df[self._get_col('revenue', 'log_slope')]
        roe_val = df[self._get_col('roe', 'latest')]

        mask_burn_cash = (rev_slope > 0.20) & (roe_val < 5.0)
        burn_cash = df[mask_burn_cash].copy()
        for _, row in burn_cash.iterrows():
            risky_list.append({
                "code": row['ts_code'], "name": row['name'], "type": "ä½æ•ˆæ‰©å¼ ",
                "desc": f"è¥æ”¶å¢é€Ÿ {row[self._get_col('revenue', 'log_slope')]:.1%} ä½† ROE ä»… {row[self._get_col('roe', 'latest')]:.1f}%"
            })

        if not risky_list:
            lines.append("*(æœªå‘ç°æ˜¾è‘—çš„äº¤å‰éªŒè¯é£é™©)*")
        else:
            lines.append("| ä»£ç  | åç§° | é£é™©ç±»å‹ | è¯¦ç»†æè¿° |")
            lines.append("|---|---|---|---|")
            # å±•ç¤ºå‰ 20 ä¸ªé£é™©æœ€å¤§çš„
            for item in risky_list[:20]:
                lines.append(f"| {item['code']} | {item['name']} | {item['type']} | {item['desc']} |")

        lines.append("")
        return lines

    def _section_industry_overview(self, df: pd.DataFrame) -> List[str]:
        """è¡Œä¸šæ™¯æ°”åº¦åˆ†æ"""
        lines = ["## ğŸ­ è¡Œä¸šæ™¯æ°”åº¦å…¨æ™¯ (Industry Heatmap)", ""]

        # è®¡ç®—å„è¡Œä¸šçš„å¹³å‡è¥æ”¶å¢é€Ÿå’Œå¹³å‡ROE
        if 'industry' not in df.columns:
            return lines

        ind_stats = df.groupby('industry').agg({
            self._get_col('revenue', 'cagr'): 'median',
            self._get_col('profit', 'cagr'): 'median',
            self._get_col('roe', 'latest'): 'median',
            'ts_code': 'count'
        }).reset_index()

        # ç­›é€‰å…¬å¸æ•° > 5 çš„è¡Œä¸š
        ind_stats = ind_stats[ind_stats['ts_code'] > 5]

        # æŒ‰æ™¯æ°”åº¦ (è¥æ”¶+åˆ©æ¶¦å¢é€Ÿ) æ’åº
        ind_stats['score'] = ind_stats[self._get_col('revenue', 'cagr')] + ind_stats[self._get_col('profit', 'cagr')]
        top_inds = ind_stats.sort_values('score', ascending=False).head(10)

        lines.append("### ğŸ”¥ é«˜æ™¯æ°”è¡Œä¸š Top 10")
        lines.append("| è¡Œä¸š | å…¬å¸æ•° | è¥æ”¶å¢é€Ÿ(ä¸­ä½æ•°) | åˆ©æ¶¦å¢é€Ÿ(ä¸­ä½æ•°) | ROE(ä¸­ä½æ•°) |")
        lines.append("|---|---|---|---|---|")

        for _, row in top_inds.iterrows():
            lines.append(f"| {row['industry']} | {row['ts_code']} | {row[self._get_col('revenue', 'cagr')]:.1%} | {row[self._get_col('profit', 'cagr')]:.1%} | {row[self._get_col('roe', 'latest')]:.1f}% |")

        lines.append("")
        return lines

