"""
è¶‹åŠ¿åˆ†æè¯¦ç»†æŠ¥å‘Šç”Ÿæˆå™¨ (v2.0)

åŠŸèƒ½ï¼š
- è¯»å–roic_trend_analysis.csv
- ç”ŸæˆåŒ…å«P0+P1+P2æ‰€æœ‰æŒ‡æ ‡çš„è¯¦ç»†MarkdownæŠ¥å‘Š
- è¾“å‡ºåˆ°data/trend_analysis_report.md

ä½œè€…: AStock Analysis System
æ—¥æœŸ: 2025-10-11
"""
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Callable, List


INFLECTION_RECOVERY = "deterioration_to_recovery"
INFLECTION_DECLINE = "growth_to_decline"
INFLECTION_LABELS = {
    INFLECTION_RECOVERY: "deterioration_to_recovery",
    INFLECTION_DECLINE: "growth_to_decline",
    'none': 'none',
}

SEVERITY_ORDER = {
    'none': 0,
    'mild': 1,
    'moderate': 2,
    'severe': 3,
}

STABLE_TYPES = {'stable', 'ultra_stable'}
VOLATILE_TYPES = {'volatile', 'high_volatility'}


def generate_trend_analysis_report(
    input_csv: str = 'data/filter_middle/roic_trend_analysis.csv',
    output_path: str = 'data/trend_analysis_report.md',
    metric_prefix: str = 'roic',
    metric_suffix: str = ''
) -> None:
    """
    ç”Ÿæˆè¶‹åŠ¿åˆ†æè¯¦ç»†æŠ¥å‘Š

    Args:
        input_csv: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºMarkdownæŠ¥å‘Šè·¯å¾„
        metric_prefix: è¶‹åŠ¿æŒ‡æ ‡å‰ç¼€ï¼ˆé»˜è®¤ roicï¼Œå¯è‡ªå®šä¹‰ä¸ºå…¶ä»–æŒ‡æ ‡ï¼‰
        metric_suffix: è¶‹åŠ¿æŒ‡æ ‡åç¼€ï¼ˆè‹¥ analyze_metric_trend è‡ªå®šä¹‰äº† suffixï¼Œå¯åœ¨æ­¤ä¼ å…¥ï¼‰
    """
    print("="*80)
    print("ğŸ“Š ç”Ÿæˆè¶‹åŠ¿åˆ†æè¯¦ç»†æŠ¥å‘Š (v2.0)".center(80))
    print("="*80)

    # è¯»å–æ•°æ®
    print(f"\nğŸ“– è¯»å–æ•°æ®: {input_csv}")
    df = pd.read_csv(input_csv)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} å®¶ä¼ä¸šæ•°æ®")

    def col(field: str) -> str:
        return f"{metric_prefix}_{field}{metric_suffix}"

    # ç”ŸæˆæŠ¥å‘Š
    report_lines = []

    # ========== æŠ¥å‘Šå¤´éƒ¨ ==========
    report_lines.extend(_generate_header(df))

    # ========== 1. æ‰§è¡Œæ‘˜è¦ ==========
    report_lines.extend(_generate_executive_summary(df, col))

    # ========== 2. P0æ³¢åŠ¨ç‡åˆ†æ ==========
    report_lines.extend(_generate_p0_volatility_analysis(df, col))

    # ========== 3. P1æ‹ç‚¹ä¸æ¶åŒ–åˆ†æ ==========
    report_lines.extend(_generate_p1_inflection_analysis(df, col))

    # ========== 4. P2å‘¨æœŸæ€§ä¸åŠ é€Ÿåº¦åˆ†æ ==========
    report_lines.extend(_generate_p2_cyclical_analysis(df, col))

    # ========== 5. è¡Œä¸šåˆ†å¸ƒåˆ†æ ==========
    report_lines.extend(_generate_industry_analysis(df, col))

    # ========== 6. æŠ•èµ„æœºä¼šè¯†åˆ« ==========
    report_lines.extend(_generate_investment_opportunities(df, col))

    # ========== 7. é£é™©è­¦ç¤º ==========
    report_lines.extend(_generate_risk_warnings(df, col))

    # ========== 8. é™„å½• ==========
    report_lines.extend(_generate_appendix(df, col))

    # å†™å…¥æ–‡ä»¶
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))

    print(f"\nâœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {output_path}")
    print(f"ğŸ“„ æŠ¥å‘Šè¡Œæ•°: {len(report_lines)}")
    print("="*80)


def _generate_header(df: pd.DataFrame) -> List[str]:
    """ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨"""
    now = datetime.now().strftime('%Y-%m-%d %H:%M')
    return [
        "# è¶‹åŠ¿åˆ†æè¯¦ç»†æŠ¥å‘Š (v2.0)",
        "",
        f"**ç”Ÿæˆæ—¶é—´**: {now}  ",
        f"**åˆ†æä¼ä¸šæ•°**: {len(df)} å®¶  ",
        f"**ç³»ç»Ÿç‰ˆæœ¬**: v2.0 (P0+P1+P2)  ",
        "",
        "---",
        ""
    ]


def _generate_executive_summary(df: pd.DataFrame, col: Callable[[str], str]) -> List[str]:
    """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
    lines = [
        "## ğŸ“Š æ‰§è¡Œæ‘˜è¦",
        "",
        "### æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ",
        ""
    ]

    # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡
    total = len(df)
    denom = total if total else 1

    # P0æŒ‡æ ‡
    volatility_col = col('volatility_type')
    log_slope_col = col('log_slope')
    has_inflection_col = col('has_inflection')
    inflection_type_col = col('inflection_type')
    has_deterioration_col = col('has_deterioration')
    is_cyclical_col = col('is_cyclical')
    is_accelerating_col = col('is_accelerating')
    is_decelerating_col = col('is_decelerating')

    stable_mask = df[volatility_col].isin(STABLE_TYPES)
    volatile_mask = df[volatility_col].isin(VOLATILE_TYPES)

    stable = stable_mask.sum()
    volatile = volatile_mask.sum()
    moderate = total - stable - volatile

    # P1æŒ‡æ ‡
    has_inflection = df[has_inflection_col].sum()
    has_deterioration = df[has_deterioration_col].sum()

    # P2æŒ‡æ ‡
    is_cyclical = df[is_cyclical_col].sum()
    is_accelerating = df[is_accelerating_col].sum()
    is_decelerating = df[is_decelerating_col].sum()

    # è¶‹åŠ¿åˆ†ç±»
    positive = (df[log_slope_col] > 0).sum()
    negative = (df[log_slope_col] < 0).sum()

    lines.extend([
        "| ç»´åº¦ | æŒ‡æ ‡ | æ•°é‡ | å æ¯” |",
        "|------|------|------|------|",
    f"| **æ€»ä½“** | é€šè¿‡ç­›é€‰ä¼ä¸š | {total} | {100.0 if total else 0.0:.1f}% |",
    f"| **è¶‹åŠ¿æ–¹å‘** | æ­£å‘å¢é•¿ | {positive} | {positive/denom*100:.1f}% |",
    f"| | è´Ÿå‘è¡°é€€ | {negative} | {negative/denom*100:.1f}% |",
    f"| **P0 æ³¢åŠ¨ç‡** | ç¨³å®šå‹ (å« ultra stable) | {stable} | {stable/denom*100:.1f}% |",
    f"| | ä¸­ç­‰æ³¢åŠ¨ | {moderate} | {moderate/denom*100:.1f}% |",
    f"| | é«˜æ³¢åŠ¨ (å« high_volatility) | {volatile} | {volatile/denom*100:.1f}% |",
    f"| **P1 æ‹ç‚¹** | æ£€å‡ºæ‹ç‚¹ | {has_inflection} | {has_inflection/denom*100:.1f}% |",
    f"| | è¿‘æœŸæ¶åŒ– | {has_deterioration} | {has_deterioration/denom*100:.1f}% |",
    f"| **P2 å‘¨æœŸæ€§** | å‘¨æœŸæ€§ä¼ä¸š | {is_cyclical} | {is_cyclical/denom*100:.1f}% |",
    f"| **P2 åŠ é€Ÿåº¦** | åŠ é€Ÿä¸Šå‡ | {is_accelerating} | {is_accelerating/denom*100:.1f}% |",
    f"| | åŠ é€Ÿä¸‹é™ | {is_decelerating} | {is_decelerating/denom*100:.1f}% |",
        "",
        "---",
        ""
    ])

    return lines


def _generate_p0_volatility_analysis(df: pd.DataFrame, col: Callable[[str], str]) -> List[str]:
    """ç”ŸæˆP0æ³¢åŠ¨ç‡åˆ†æ"""
    lines = [
        "## ğŸ“ˆ P0: æ³¢åŠ¨ç‡åˆ†æ",
        "",
        "### æ³¢åŠ¨ç‡ç±»å‹åˆ†å¸ƒ",
        ""
    ]

    # æ³¢åŠ¨ç‡ç»Ÿè®¡
    volatility_col = col('volatility_type')
    cv_col = col('cv')
    std_col = col('std_dev')

    stable = df[df[volatility_col].isin(STABLE_TYPES)]
    moderate = df[df[volatility_col] == 'moderate']
    volatile = df[df[volatility_col].isin(VOLATILE_TYPES)]

    lines.extend([
        f"- **ç¨³å®šå‹ä¼ä¸š** ({len(stable)}å®¶): å˜å¼‚ç³»æ•°åˆ†å¸ƒäºç¨³å®šåŒºé—´",
        f"- **ä¸­ç­‰æ³¢åŠ¨ä¼ä¸š** ({len(moderate)}å®¶)",
        f"- **é«˜æ³¢åŠ¨ä¼ä¸š** ({len(volatile)}å®¶): åŒ…å« volatile/high_volatility",
        "",
        "### æ³¢åŠ¨ç‡ç»Ÿè®¡æŒ‡æ ‡",
        "",
        "| æŒ‡æ ‡ | å‡å€¼ | ä¸­ä½æ•° | æœ€å°å€¼ | æœ€å¤§å€¼ |",
        "|------|------|--------|--------|--------|",
        f"| å˜å¼‚ç³»æ•° (CV) | {df[cv_col].mean():.3f} | {df[cv_col].median():.3f} | {df[cv_col].min():.3f} | {df[cv_col].max():.3f} |",
        f"| æ ‡å‡†å·® | {df[std_col].mean():.3f} | {df[std_col].median():.3f} | {df[std_col].min():.3f} | {df[std_col].max():.3f} |",
        "",
        "### ğŸŒŸ æœ€ç¨³å®šä¼ä¸š TOP10 (CVæœ€ä½)",
        ""
    ])

    # æœ€ç¨³å®šä¼ä¸š
    top_stable = stable.nsmallest(10, cv_col)
    for idx, (_, row) in enumerate(top_stable.iterrows(), 1):
        name = row.get('name', row['ts_code'])
        cv = row[cv_col]
        slope = row[col('log_slope')]
        industry = row.get('industry', 'N/A')
        lines.append(f"{idx}. **{name}** ({row['ts_code']}) - CV: {cv:.3f}, æ–œç‡: {slope:.3f}, è¡Œä¸š: {industry}")

    lines.extend(["", "---", ""])
    return lines


def _generate_p1_inflection_analysis(df: pd.DataFrame, col: Callable[[str], str]) -> List[str]:
    """ç”ŸæˆP1æ‹ç‚¹ä¸æ¶åŒ–åˆ†æ"""
    lines = [
        "## ğŸ”„ P1: æ‹ç‚¹ä¸æ¶åŒ–åˆ†æ",
        "",
        "### æ‹ç‚¹æ£€æµ‹ç»“æœ",
        ""
    ]

    has_inflection_col = col('has_inflection')
    inflection_type_col = col('inflection_type')
    slope_change_col = col('slope_change')
    inflection_confidence_col = col('inflection_confidence')
    has_deterioration_col = col('has_deterioration')
    deterioration_severity_col = col('deterioration_severity')
    total_decline_col = col('total_decline_pct')

    has_inflection = df[df[has_inflection_col]].copy()
    no_inflection = df[~df[has_inflection_col]].copy()
    total = len(df)
    denom = total if total else 1

    lines.extend([
        f"- **æ£€å‡ºæ‹ç‚¹**: {len(has_inflection)} å®¶ ({len(has_inflection)/denom*100:.1f}%)",
        f"- **æ— æ‹ç‚¹**: {len(no_inflection)} å®¶ ({len(no_inflection)/denom*100:.1f}%)",
        "",
        "### æ‹ç‚¹ç±»å‹åˆ†å¸ƒ",
        ""
    ])

    if not has_inflection.empty:
        inflection_types = has_inflection[inflection_type_col].value_counts()
        for inflection_type, count in inflection_types.items():
            pct = count / len(has_inflection) * 100 if len(has_inflection) else 0.0
            emoji = "ğŸ“ˆ" if inflection_type == INFLECTION_RECOVERY else "ğŸ“‰"
            lines.append(f"- {emoji} **{inflection_type}**: {count} å®¶ ({pct:.1f}%)")

        lines.extend([
            "",
            "### ğŸ¯ æ‹ç‚¹åè½¬æœºä¼š (æ¶åŒ–â†’å¥½è½¬)",
            ""
        ])

        reversal = has_inflection[has_inflection[inflection_type_col] == INFLECTION_RECOVERY]
        if not reversal.empty:
            top_reversal = reversal.nlargest(10, slope_change_col)
            for idx, (_, row) in enumerate(top_reversal.iterrows(), 1):
                name = row.get('name', row['ts_code'])
                change = row[slope_change_col]
                confidence = row[inflection_confidence_col]
                lines.append(f"{idx}. **{name}** - æ–œç‡æ”¹å–„: {change:.2f}, ç½®ä¿¡åº¦: {confidence:.2f}")

    lines.extend([
        "",
        "### âš ï¸ è¿‘æœŸæ¶åŒ–é¢„è­¦",
        ""
    ])

    deterioration = df[df[has_deterioration_col]].copy()
    lines.append(f"**æ£€å‡ºè¿‘æœŸæ¶åŒ–**: {len(deterioration)} å®¶ ({len(deterioration)/denom*100:.1f}%)")
    lines.append("")

    if not deterioration.empty:
        deterioration['severity_score'] = deterioration[deterioration_severity_col].map(SEVERITY_ORDER).fillna(-1)
        top_deterioration = deterioration.sort_values(
            ['severity_score', total_decline_col], ascending=[False, True]
        ).head(10)
        for idx, (_, row) in enumerate(top_deterioration.iterrows(), 1):
            name = row.get('name', row['ts_code'])
            severity = row[deterioration_severity_col]
            total_decline = row[total_decline_col]
            if row['severity_score'] >= 0:
                lines.append(
                    f"{idx}. **{name}** - æ¶åŒ–ä¸¥é‡åº¦: {severity}, æ€»è·Œå¹…: {total_decline:.1f}%"
                )

    lines.extend(["", "---", ""])
    return lines


def _generate_p2_cyclical_analysis(df: pd.DataFrame, col: Callable[[str], str]) -> List[str]:
    """ç”ŸæˆP2å‘¨æœŸæ€§ä¸åŠ é€Ÿåº¦åˆ†æ"""
    lines = [
        "## ğŸ”„ P2: å‘¨æœŸæ€§ä¸åŠ é€Ÿåº¦åˆ†æ",
        "",
        "### å‘¨æœŸæ€§ä¼ä¸šè¯†åˆ«",
        ""
    ]

    # å‘¨æœŸæ€§ç»Ÿè®¡
    is_cyclical_col = col('is_cyclical')
    current_phase_col = col('current_phase')
    peak_to_trough_col = col('peak_to_trough_ratio')
    log_slope_col = col('log_slope')
    trend_acceleration_col = col('trend_acceleration')
    is_accelerating_col = col('is_accelerating')
    is_decelerating_col = col('is_decelerating')
    recent_3y_slope_col = col('recent_3y_slope')

    cyclical = df[df[is_cyclical_col]]
    non_cyclical = df[~df[is_cyclical_col]]
    total = len(df)
    denom = total if total else 1

    lines.extend([
    f"- **å‘¨æœŸæ€§ä¼ä¸š**: {len(cyclical)} å®¶ ({len(cyclical)/denom*100:.1f}%)",
    f"- **éå‘¨æœŸæ€§ä¼ä¸š**: {len(non_cyclical)} å®¶ ({len(non_cyclical)/denom*100:.1f}%)",
        "",
        "### å‘¨æœŸé˜¶æ®µåˆ†å¸ƒ",
        ""
    ])

    if len(cyclical) > 0:
        phase_counts = cyclical[current_phase_col].value_counts()
        phase_emoji = {
            'trough': 'ğŸ”½ åº•éƒ¨',
            'peak': 'ğŸ”¼ é¡¶éƒ¨',
            'rising': 'ğŸ“ˆ ä¸Šå‡',
            'falling': 'ğŸ“‰ ä¸‹é™',
            'unknown': 'â“ æœªçŸ¥'
        }

        for phase, count in phase_counts.items():
            pct = count / len(cyclical) * 100
            emoji = phase_emoji.get(phase, phase)
            lines.append(f"- {emoji}: {count} å®¶ ({pct:.1f}%)")

        lines.extend([
            "",
            "### ğŸ’ å‘¨æœŸåº•éƒ¨æœºä¼š (å³°è°·æ¯”>3)",
            ""
        ])

        # å‘¨æœŸåº•éƒ¨ä¼ä¸š
        trough = cyclical[cyclical[current_phase_col] == 'trough']
        if len(trough) > 0:
            top_trough = trough.nlargest(10, peak_to_trough_col)
            for idx, (_, row) in enumerate(top_trough.iterrows(), 1):
                name = row.get('name', row['ts_code'])
                ratio = row[peak_to_trough_col]
                slope = row[log_slope_col]
                industry = row.get('industry', 'N/A')
                lines.append(f"{idx}. **{name}** - å³°è°·æ¯”: {ratio:.2f}, æ–œç‡: {slope:.3f}, è¡Œä¸š: {industry}")

    lines.extend([
        "",
        "### ğŸš€ è¶‹åŠ¿åŠ é€Ÿåº¦åˆ†æ",
        ""
    ])

    # åŠ é€Ÿåº¦ç»Ÿè®¡
    accelerating = df[df[is_accelerating_col]]
    decelerating = df[df[is_decelerating_col]]
    stable_trend = df[~(df[is_accelerating_col] | df[is_decelerating_col])]

    lines.extend([
        f"- **åŠ é€Ÿä¸Šå‡**: {len(accelerating)} å®¶ ({len(accelerating)/len(df)*100:.1f}%)",
        f"- **åŠ é€Ÿä¸‹é™**: {len(decelerating)} å®¶ ({len(decelerating)/len(df)*100:.1f}%)",
        f"- **è¶‹åŠ¿ç¨³å®š**: {len(stable_trend)} å®¶ ({len(stable_trend)/len(df)*100:.1f}%)",
        "",
        "### âš¡ åŠ é€Ÿä¸Šå‡ä¼ä¸š TOP10",
        ""
    ])

    if len(accelerating) > 0:
        top_accelerating = accelerating.nlargest(10, trend_acceleration_col)
        for idx, (_, row) in enumerate(top_accelerating.iterrows(), 1):
            name = row.get('name', row['ts_code'])
            acc = row[trend_acceleration_col]
            slope_3y = row[recent_3y_slope_col]
            lines.append(f"{idx}. **{name}** - åŠ é€Ÿåº¦: {acc:.2f}, 3å¹´æ–œç‡: {slope_3y:.3f}")

    lines.extend(["", "---", ""])
    return lines


def _generate_industry_analysis(df: pd.DataFrame, col: Callable[[str], str]) -> List[str]:
    """ç”Ÿæˆè¡Œä¸šåˆ†å¸ƒåˆ†æ"""
    lines = [
        "## ğŸ­ è¡Œä¸šåˆ†å¸ƒåˆ†æ",
        "",
        "### è¡Œä¸šä¼ä¸šæ•°é‡åˆ†å¸ƒ TOP15",
        ""
    ]

    if 'industry' in df.columns:
        industry_counts = df['industry'].value_counts().head(15)
        denom = len(df) if len(df) else 1

        lines.append("| æ’å | è¡Œä¸š | ä¼ä¸šæ•° | å æ¯” |")
        lines.append("|------|------|--------|------|")

        for idx, (industry, count) in enumerate(industry_counts.items(), 1):
            pct = count / denom * 100
            lines.append(f"| {idx} | {industry} | {count} | {pct:.1f}% |")

        lines.extend([
            "",
            "### è¡Œä¸šå¹³å‡ROICè¶‹åŠ¿æ–œç‡ TOP10",
            ""
        ])

        # è¡Œä¸šå¹³å‡æ–œç‡
        industry_slope = df.groupby('industry')[col('log_slope')].agg(['mean', 'count']).reset_index()
        industry_slope = industry_slope[industry_slope['count'] >= 3]  # è‡³å°‘3å®¶ä¼ä¸š
        top_industries = industry_slope.nlargest(10, 'mean')

        lines.append("| æ’å | è¡Œä¸š | å¹³å‡æ–œç‡ | ä¼ä¸šæ•° |")
        lines.append("|------|------|----------|--------|")

        for idx, row in enumerate(top_industries.itertuples(), 1):
            lines.append(f"| {idx} | {row.industry} | {row.mean:.3f} | {int(row.count)} |")
    else:
        lines.append("_è¡Œä¸šä¿¡æ¯ä¸å¯ç”¨_")

    lines.extend(["", "---", ""])
    return lines


def _generate_investment_opportunities(df: pd.DataFrame, col: Callable[[str], str]) -> List[str]:
    """ç”ŸæˆæŠ•èµ„æœºä¼šè¯†åˆ«"""
    lines = [
        "## ğŸ’ æŠ•èµ„æœºä¼šè¯†åˆ«",
        "",
        "### æœºä¼šç±»å‹1: å‘¨æœŸåº•éƒ¨+åŠ é€Ÿä¸Šå‡ (æœ€ä¼˜æœºä¼š)",
        ""
    ]

    # å‘¨æœŸåº•éƒ¨+åŠ é€Ÿä¸Šå‡
    opportunity1 = df[
        (df[col('is_cyclical')]) &
        (df[col('current_phase')] == 'trough') &
        (df[col('is_accelerating')])
    ]

    lines.append(f"**æ•°é‡**: {len(opportunity1)} å®¶")
    lines.append("")

    if len(opportunity1) > 0:
        for idx, (_, row) in enumerate(opportunity1.iterrows(), 1):
            name = row.get('name', row['ts_code'])
            slope = row[col('log_slope')]
            acc = row[col('trend_acceleration')]
            ratio = row[col('peak_to_trough_ratio')]
            lines.append(f"{idx}. **{name}** - æ–œç‡: {slope:.3f}, åŠ é€Ÿåº¦: {acc:.2f}, å³°è°·æ¯”: {ratio:.2f}")
    else:
        lines.append("_æš‚æ— ç¬¦åˆæ¡ä»¶çš„ä¼ä¸š_")

    lines.extend([
        "",
        "### æœºä¼šç±»å‹2: æ‹ç‚¹åè½¬+ä½æ³¢åŠ¨ (ç¨³å¥æœºä¼š)",
        ""
    ])

    # æ‹ç‚¹åè½¬+ä½æ³¢åŠ¨
    opportunity2 = df[
        (df[col('has_inflection')]) &
        (df[col('inflection_type')] == INFLECTION_RECOVERY) &
        (df[col('volatility_type')].isin(STABLE_TYPES))
    ].nlargest(10, col('slope_change'))

    lines.append(f"**æ•°é‡**: {len(opportunity2)} å®¶ (å±•ç¤ºTOP10)")
    lines.append("")

    if len(opportunity2) > 0:
        for idx, (_, row) in enumerate(opportunity2.iterrows(), 1):
            name = row.get('name', row['ts_code'])
            change = row[col('slope_change')]
            cv = row[col('cv')]
            lines.append(f"{idx}. **{name}** - æ–œç‡æ”¹å–„: {change:.2f}, CV: {cv:.3f}")
    else:
        lines.append("_æš‚æ— ç¬¦åˆæ¡ä»¶çš„ä¼ä¸š_")

    lines.extend([
        "",
        "### æœºä¼šç±»å‹3: éå‘¨æœŸ+åŠ é€Ÿ+ä½æ³¢åŠ¨ (æˆé•¿æœºä¼š)",
        ""
    ])

    # éå‘¨æœŸ+åŠ é€Ÿ+ä½æ³¢åŠ¨
    opportunity3 = df[
        (~df[col('is_cyclical')]) &
        (df[col('is_accelerating')]) &
        (df[col('volatility_type')].isin(STABLE_TYPES)) &
        (df[col('log_slope')] > 0)
    ].nlargest(10, col('trend_acceleration'))

    lines.append(f"**æ•°é‡**: {len(opportunity3)} å®¶ (å±•ç¤ºTOP10)")
    lines.append("")

    if len(opportunity3) > 0:
        for idx, (_, row) in enumerate(opportunity3.iterrows(), 1):
            name = row.get('name', row['ts_code'])
            acc = row[col('trend_acceleration')]
            slope = row[col('log_slope')]
            cv = row[col('cv')]
            lines.append(f"{idx}. **{name}** - åŠ é€Ÿåº¦: {acc:.2f}, æ–œç‡: {slope:.3f}, CV: {cv:.3f}")
    else:
        lines.append("_æš‚æ— ç¬¦åˆæ¡ä»¶çš„ä¼ä¸š_")

    lines.extend(["", "---", ""])
    return lines


def _generate_risk_warnings(df: pd.DataFrame, col: Callable[[str], str]) -> List[str]:
    """ç”Ÿæˆé£é™©è­¦ç¤º"""
    lines = [
        "## âš ï¸ é£é™©è­¦ç¤º",
        "",
        "### é£é™©ç±»å‹1: å‘¨æœŸé¡¶éƒ¨é¢„è­¦",
        ""
    ]

    # å‘¨æœŸé¡¶éƒ¨
    risk1 = df[
        (df[col('is_cyclical')]) &
        (df[col('current_phase')] == 'peak')
    ].nlargest(10, col('peak_to_trough_ratio'))

    lines.append(f"**æ•°é‡**: {len(risk1)} å®¶ (å±•ç¤ºTOP10)")
    lines.append("")

    if len(risk1) > 0:
        for idx, (_, row) in enumerate(risk1.iterrows(), 1):
            name = row.get('name', row['ts_code'])
            ratio = row[col('peak_to_trough_ratio')]
            slope = row[col('log_slope')]
            lines.append(f"{idx}. **{name}** - å³°è°·æ¯”: {ratio:.2f}, æ–œç‡: {slope:.3f}")
    else:
        lines.append("_æš‚æ— é£é™©é¢„è­¦_")

    lines.extend([
        "",
        "### é£é™©ç±»å‹2: åŠ é€Ÿæ¶åŒ–+è¿‘æœŸæ¶åŒ–",
        ""
    ])

    # åŠ é€Ÿæ¶åŒ–+è¿‘æœŸæ¶åŒ–
    risk2_temp = df[
        (df[col('is_decelerating')]) &
        (df[col('has_deterioration')])
    ].copy()
    risk2_temp['severity_score'] = risk2_temp[col('deterioration_severity')].map(SEVERITY_ORDER).fillna(-1)
    risk2 = risk2_temp.sort_values(
        ['severity_score', col('trend_acceleration')], ascending=[False, True]
    ).head(10)

    lines.append(f"**æ•°é‡**: {len(risk2_temp)} å®¶ (å±•ç¤ºTOP10)")
    lines.append("")

    if len(risk2) > 0:
        for idx, (_, row) in enumerate(risk2.iterrows(), 1):
            name = row.get('name', row['ts_code'])
            acc = row[col('trend_acceleration')]
            severity = row[col('deterioration_severity')]
            if row['severity_score'] >= 0:
                lines.append(f"{idx}. **{name}** - åŠ é€Ÿåº¦: {acc:.2f}, æ¶åŒ–ä¸¥é‡åº¦: {severity}")
    else:
        lines.append("_æš‚æ— é£é™©é¢„è­¦_")

    lines.extend([
        "",
        "### é£é™©ç±»å‹3: é«˜æ³¢åŠ¨+è´Ÿè¶‹åŠ¿",
        ""
    ])

    # é«˜æ³¢åŠ¨+è´Ÿè¶‹åŠ¿
    risk3 = df[
        (df[col('volatility_type')].isin(VOLATILE_TYPES)) &
        (df[col('log_slope')] < 0)
    ].nsmallest(10, col('log_slope'))

    lines.append(f"**æ•°é‡**: {len(risk3)} å®¶ (å±•ç¤ºTOP10)")
    lines.append("")

    if len(risk3) > 0:
        for idx, (_, row) in enumerate(risk3.iterrows(), 1):
            name = row.get('name', row['ts_code'])
            cv = row[col('cv')]
            slope = row[col('log_slope')]
            lines.append(f"{idx}. **{name}** - CV: {cv:.3f}, æ–œç‡: {slope:.3f}")
    else:
        lines.append("_æš‚æ— é£é™©é¢„è­¦_")

    lines.extend(["", "---", ""])
    return lines


def _generate_appendix(df: pd.DataFrame, col: Callable[[str], str]) -> List[str]:
    """ç”Ÿæˆé™„å½•"""
    lines = [
        "## ğŸ“š é™„å½•",
        "",
        "### æŒ‡æ ‡è¯´æ˜",
        "",
    "#### P0 æ³¢åŠ¨ç‡æŒ‡æ ‡",
    f"- **{col('cv')}**: å˜å¼‚ç³»æ•° (æ ‡å‡†å·®/å‡å€¼)",
    f"- **{col('std_dev')}**: æ ‡å‡†å·®",
    f"- **{col('volatility_type')}**: æ³¢åŠ¨ç±»å‹åˆ†ç±»",
        "",
        "#### P1 æ‹ç‚¹æŒ‡æ ‡",
    f"- **{col('has_inflection')}**: æ˜¯å¦å­˜åœ¨æ‹ç‚¹",
    f"- **{col('inflection_type')}**: æ‹ç‚¹ç±»å‹",
    f"- **{col('early_slope')}**: å‰æœŸæ–œç‡",
    f"- **{col('recent_slope')}**: åæœŸæ–œç‡",
    f"- **{col('slope_change')}**: æ–œç‡å˜åŒ–é‡",
    f"- **{col('inflection_confidence')}**: æ‹ç‚¹ç½®ä¿¡åº¦",
    f"- **{col('has_deterioration')}**: æ˜¯å¦è¿‘æœŸæ¶åŒ–",
    f"- **{col('deterioration_severity')}**: æ¶åŒ–ä¸¥é‡åº¦",
        "",
        "#### P2 å‘¨æœŸæ€§æŒ‡æ ‡",
    f"- **{col('is_cyclical')}**: æ˜¯å¦å‘¨æœŸæ€§ä¼ä¸š",
    f"- **{col('peak_to_trough_ratio')}**: å³°è°·æ¯”",
    f"- **{col('current_phase')}**: å½“å‰å‘¨æœŸé˜¶æ®µ (trough/peak/rising/falling)",
    f"- **{col('recent_3y_slope')}**: æœ€è¿‘3å¹´æ–œç‡",
    f"- **{col('trend_acceleration')}**: è¶‹åŠ¿åŠ é€Ÿåº¦",
    f"- **{col('is_accelerating')}**: æ˜¯å¦åŠ é€Ÿä¸Šå‡",
    f"- **{col('is_decelerating')}**: æ˜¯å¦åŠ é€Ÿä¸‹é™",
        "",
        "### æ•°æ®ç»Ÿè®¡",
        "",
        f"- **æ€»ä¼ä¸šæ•°**: {len(df)} å®¶",
        f"- **åˆ†æå¹´ä»½**: 5å¹´ (2020-2024)",
        f"- **æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "---",
        "",
        "*æœ¬æŠ¥å‘Šç”± AStock Analysis System v2.0 è‡ªåŠ¨ç”Ÿæˆ*"
    ]

    return lines


if __name__ == '__main__':
    # æµ‹è¯•è¿è¡Œ
    generate_trend_analysis_report()
