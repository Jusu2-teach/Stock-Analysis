"""ConfigService: è´Ÿè´£é…ç½®åŠ è½½/è§£æ/æ‹“æ‰‘/èŠ‚ç‚¹æ„å»º

èŒè´£ï¼š
1. åŠ è½½å’Œè§£æ YAML é…ç½®æ–‡ä»¶
2. æ„å»º StepSpec è§„èŒƒå¯¹è±¡
3. ä½¿ç”¨ DependencyGraph è®¡ç®—æ‰§è¡Œé¡ºåº
4. ç”Ÿæˆ Kedro å…¼å®¹çš„èŠ‚ç‚¹é…ç½®

è®¾è®¡åŸåˆ™ï¼š
- å•ä¸€èŒè´£ï¼šåªè´Ÿè´£é…ç½®è§£æï¼Œä¸æ‰§è¡Œä»»ä½•ä¸šåŠ¡é€»è¾‘
- ä¾èµ–åè½¬ï¼šé€šè¿‡ PipelineContext å…±äº«çŠ¶æ€
- å¼€é—­åŸåˆ™ï¼šé€šè¿‡ DependencySource æ‰©å±•ä¾èµ–è§£æ

é‡æ„ä¸ºä¾èµ– PipelineContext è€Œé ExecuteManagerï¼Œé™ä½è€¦åˆã€‚
"""
from __future__ import annotations
from typing import Any, Dict, List, Set
from collections import defaultdict
import yaml
import hashlib
import re
import logging

from ..context import PipelineContext, StepSpec, StepOutput
from ..dependency_graph import (
    DependencyGraph,
    DependencyType,
    DependencySource,
    DependencyEdge,
    ExecutionPlan,
    CyclicDependencyError,
    # âœ… ä½¿ç”¨ç»Ÿä¸€çš„ä¾èµ–æºå®ç°ï¼ˆä¸å†é‡å¤å®šä¹‰ï¼‰
    DataDependencySource,
    ExplicitDependencySource,
)


# ============================================================================
# ğŸ”„ é‡æ„è¯´æ˜ï¼š
# StepDataDependencySource å’Œ StepExplicitDependencySource å·²ç§»é™¤ã€‚
# ç°åœ¨ç›´æ¥ä½¿ç”¨ dependency_graph.py ä¸­çš„ DataDependencySource å’Œ
# ExplicitDependencySourceï¼Œå®ƒä»¬çš„å®ç°æ˜¯å®Œå…¨ç­‰ä»·çš„ã€‚
# è¿™æ¶ˆé™¤äº†ä»£ç é‡å¤ï¼Œéµå¾ª DRY åŸåˆ™ã€‚
# ============================================================================


class ConfigService:
    """é…ç½®æœåŠ¡ï¼ˆä¸“ä¸šçº§å®ç°ï¼‰

    é€šè¿‡ PipelineContext è®¿é—®å…±äº«çŠ¶æ€ï¼Œä½¿ç”¨ DependencyGraph ç®¡ç†ä¾èµ–ã€‚

    æ ¸å¿ƒæµç¨‹ï¼š
    1. load_config() -> è§£æ YAML
    2. _parse_steps() -> æ„å»º StepSpec
    3. _build_dependency_graph() -> åˆ›å»ºä¾èµ–å›¾
    4. _compute_execution_order() -> æ‹“æ‰‘æ’åº
    """

    __slots__ = ('ctx', 'logger', '_dependency_graph')

    # æ­¥éª¤å¼•ç”¨æ¨¡å¼ï¼šsteps.<step_name>.outputs.parameters.<param_name>
    REF_PATTERN = re.compile(r"^steps\.(?P<step>[^.]+)\.outputs\.parameters\.(?P<param>[^.]+)$")

    def __init__(self, context: PipelineContext, logger: logging.Logger | None = None):
        self.ctx = context
        self.logger = logger or logging.getLogger(__name__)
        self._dependency_graph: DependencyGraph | None = None

    @property
    def dependency_graph(self) -> DependencyGraph | None:
        """è·å–ä¾èµ–å›¾ï¼ˆåªè¯»è®¿é—®ï¼‰"""
        return self._dependency_graph

    # ========== Public API ==========

    def load_config(self, path: str) -> Dict[str, Any]:
        """åŠ è½½å¹¶è§£æé…ç½®æ–‡ä»¶

        Args:
            path: YAML é…ç½®æ–‡ä»¶è·¯å¾„

        Returns:
            è§£æåçš„é…ç½®å­—å…¸
        """
        with open(path, 'r', encoding='utf-8') as f:
            self.ctx.config = yaml.safe_load(f)
        self.logger.info(f"ğŸ§¾ å·²åŠ è½½é…ç½®: {path}")

        self._parse_steps()
        self._build_dependency_graph()
        self._compute_execution_order()

        return self.ctx.config

    def get_execution_plan(self) -> ExecutionPlan:
        """è·å–æ‰§è¡Œè®¡åˆ’

        Returns:
            ExecutionPlan å®ä¾‹ï¼ŒåŒ…å«å±‚æ¬¡ä¿¡æ¯å’Œå…³é”®è·¯å¾„
        """
        if self._dependency_graph is None:
            raise RuntimeError("ä¾èµ–å›¾æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ load_config()")
        return self._dependency_graph.build_execution_plan()

    # ========== Internal: Step Parsing ==========

    def _parse_steps(self):
        """è§£æé…ç½®ä¸­çš„æ­¥éª¤å®šä¹‰"""
        self.ctx.steps.clear()
        pipeline = self.ctx.config.get('pipeline', {}) if self.ctx.config else {}
        raw_steps = pipeline.get('steps') or self.ctx.config.get('steps')
        if not isinstance(raw_steps, list):
            raise ValueError("é…ç½®ä¸­ pipeline.steps å¿…é¡»ä¸ºåˆ—è¡¨")

        # é¢„æ‰«æå¼•ç”¨
        referenced_map: Dict[str, Set[str]] = defaultdict(set)

        def collect_refs(val: Any):
            if isinstance(val, str):
                m = self.REF_PATTERN.match(val.strip())
                if m:
                    referenced_map[m.group('step')].add(m.group('param'))
            elif isinstance(val, list):
                for x in val:
                    collect_refs(x)
            elif isinstance(val, dict):
                for v in val.values():
                    collect_refs(v)

        for raw in raw_steps:
            if not isinstance(raw, dict):
                continue
            cand_params = {}
            if 'arguments' in raw and isinstance(raw['arguments'], dict):
                cand_params.update(raw['arguments'].get('parameters', {}) or {})
            cand_params.update(raw.get('parameters', {}) or {})
            for v in cand_params.values():
                collect_refs(v)

        for idx, raw in enumerate(raw_steps):
            if not isinstance(raw, dict):
                continue
            name = raw.get('name') or f"step_{idx}"
            component = raw['component']
            # å¼•æ“å¯çœç•¥æˆ–å†™ auto -> ç”± orchestrator åŠ¨æ€è§£æ
            engine = raw.get('engine', 'auto') or 'auto'
            methods = raw.get('method', [])
            if isinstance(methods, str):
                methods = [methods]
            params = {}
            if 'arguments' in raw and isinstance(raw['arguments'], dict):
                params.update(raw['arguments'].get('parameters', {}) or {})
            params.update(raw.get('parameters', {}) or {})

            outputs: List[StepOutput] = []
            out_section = raw.get('outputs', {})
            param_outputs = out_section.get('parameters', []) if isinstance(out_section, dict) else []
            if isinstance(param_outputs, list):
                for item in param_outputs:
                    if isinstance(item, dict):
                        outputs.append(StepOutput(name=str(item['name']), source_key=item.get('from')))
                    elif isinstance(item, str):
                        outputs.append(StepOutput(name=item))
            elif isinstance(param_outputs, dict):
                for k, v in param_outputs.items():
                    if isinstance(v, dict):
                        outputs.append(StepOutput(name=k, source_key=v.get('from')))
                    else:
                        outputs.append(StepOutput(name=k))

            if not outputs and name in referenced_map:
                auto_outputs = [StepOutput(name=p) for p in sorted(referenced_map[name])]
                outputs.extend(auto_outputs)
                self.logger.info(f"ğŸ§© è‡ªåŠ¨è¡¥å…¨éšå¼ outputs: step={name} -> {[o.name for o in auto_outputs]}")

            # è§£ææ˜¾å¼ä¾èµ–å£°æ˜
            explicit_deps = raw.get('depends_on', [])
            if isinstance(explicit_deps, str):
                explicit_deps = [explicit_deps]

            spec = StepSpec(
                name=name,
                component=component,
                engine=engine,
                methods=methods,
                raw_parameters=self._mark_references(params),
                outputs=outputs,
                depends_on=explicit_deps
            )
            self.ctx.steps[name] = spec

    def _mark_references(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """æ ‡è®°å‚æ•°ä¸­çš„å¼•ç”¨"""
        def walk(val):
            if isinstance(val, str):
                m = self.REF_PATTERN.match(val.strip())
                if m:
                    ref = val.strip()
                    ghash = self._hash_reference(ref)
                    self.ctx.reference_to_hash.setdefault(ref, ghash)
                    return {"__ref__": ref, "hash": ghash}
                return val
            if isinstance(val, list):
                return [walk(v) for v in val]
            if isinstance(val, dict):
                return {k: walk(v) for k, v in val.items()}
            return val
        return {k: walk(v) for k, v in params.items()}

    def _hash_reference(self, ref: str) -> str:
        """ç”Ÿæˆå¼•ç”¨çš„å“ˆå¸Œå€¼"""
        return hashlib.md5(ref.encode('utf-8')).hexdigest()[:16]

    # ========== Internal: Dependency Graph ==========

    def _build_dependency_graph(self) -> None:
        """æ„å»ºä¾èµ–å›¾

        ä½¿ç”¨ä¸“ä¸šçš„ DependencyGraph ç±»ç®¡ç†ä¾èµ–å…³ç³»ã€‚
        è¿™æ˜¯å•ä¸€èŒè´£ï¼šä¾èµ–å›¾åªè´Ÿè´£ä¾èµ–å»ºæ¨¡å’Œæ‹“æ‰‘æ’åºã€‚
        """
        # å°† StepSpec è½¬æ¢ä¸ºèŠ‚ç‚¹é…ç½®æ ¼å¼ï¼ˆç”¨äº DependencySourceï¼‰
        node_configs = {}
        for name, spec in self.ctx.steps.items():
            # æ”¶é›†æ•°æ®é›†è¾“å…¥
            inputs = []
            for pval in spec.raw_parameters.values():
                for ref in self._extract_refs(pval):
                    m = self.REF_PATTERN.match(ref)
                    if m:
                        ds_name = self.ctx.dataset_name(m.group('step'), m.group('param'))
                        inputs.append(ds_name)

            # æ”¶é›†æ•°æ®é›†è¾“å‡º
            outputs = [self.ctx.dataset_name(name, o.name) for o in spec.outputs]

            node_configs[name] = {
                'inputs': inputs,
                'outputs': outputs,
                'depends_on': spec.depends_on,
            }

        # ä½¿ç”¨ä¾èµ–æºç­–ç•¥åˆ›å»ºä¾èµ–å›¾ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„ DependencySource å®ç°ï¼‰
        self._dependency_graph = DependencyGraph.from_node_configs(
            node_configs,
            sources=[
                DataDependencySource(),      # âœ… ä½¿ç”¨ç»Ÿä¸€å®ç°
                ExplicitDependencySource(),  # âœ… ä½¿ç”¨ç»Ÿä¸€å®ç°
            ],
            logger=self.logger
        )

        # âœ… å°†ä¾èµ–å›¾å­˜å‚¨åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼ˆä¾›å…¶ä»–ç»„ä»¶å¤ç”¨ï¼Œé¿å…é‡å¤æ„å»ºï¼‰
        self.ctx.set_dependency_graph(self._dependency_graph)

        # è®°å½•æ˜¾å¼ä¾èµ–ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
        for name, spec in self.ctx.steps.items():
            if spec.depends_on:
                self.logger.info(f"ğŸ“Œ æ˜¾å¼ä¾èµ–: {name} -> {spec.depends_on}")

    def _compute_execution_order(self) -> None:
        """è®¡ç®—æ­¥éª¤æ‰§è¡Œé¡ºåº

        ä½¿ç”¨ DependencyGraph çš„æ‹“æ‰‘æ’åºåŠŸèƒ½ï¼Œæä¾›ï¼š
        - å¾ªç¯ä¾èµ–æ£€æµ‹
        - å±‚æ¬¡åŒ–æ‰§è¡Œè®¡åˆ’
        - å…³é”®è·¯å¾„åˆ†æ
        """
        if self._dependency_graph is None:
            raise RuntimeError("ä¾èµ–å›¾æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ _build_dependency_graph()")

        try:
            plan = self._dependency_graph.build_execution_plan()
            self.ctx.execution_order = plan.flatten()

            # âœ… ä½¿ç”¨ä¸“ç”¨æ–¹æ³•å­˜å‚¨æ‰§è¡Œè®¡åˆ’ï¼ˆä¾› Prefect Engine ä½¿ç”¨ï¼‰
            self.ctx.set_execution_plan(plan)

            self.logger.info(f"ğŸ§­ æ‰§è¡Œé¡ºåº: {self.ctx.execution_order}")
            self.logger.info(f"ğŸ“Š æ‰§è¡Œè®¡åˆ’: {plan.depth} å±‚, æœ€å¤§å¹¶è¡Œåº¦ {plan.max_parallelism}")

            if plan.critical_path:
                self.logger.debug(f"ğŸ”¥ å…³é”®è·¯å¾„: {' -> '.join(plan.critical_path)}")

        except CyclicDependencyError as e:
            raise ValueError(f"æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–: {e.cycle}") from e

    def _extract_refs(self, val) -> List[str]:
        """é€’å½’æå–å¼•ç”¨æ ‡è®°"""
        refs = []
        if isinstance(val, dict):
            if '__ref__' in val:
                refs.append(val['__ref__'])
            else:
                for v in val.values():
                    refs.extend(self._extract_refs(v))
        elif isinstance(val, list):
            for v in val:
                refs.extend(self._extract_refs(v))
        return refs

    # ========== Internal: Node Config Building ==========

    def build_auto_nodes(self) -> Dict[str, Any]:
        """æ„å»ºè‡ªåŠ¨èŠ‚ç‚¹é…ç½®"""
        auto_nodes = []

        for step_name in self.ctx.execution_order:
            spec = self.ctx.steps[step_name]
            resolved_params = dict(spec.raw_parameters)
            node_outs = [self.ctx.dataset_name(spec.name, o.name) for o in spec.outputs]

            # ä½¿ç”¨å·¥å‚æ–¹æ³•åˆ›å»º MethodHandleï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
            engine_val = spec.engine
            handles = []

            if not spec.methods:
                raise ValueError(f"step æœªæä¾› methods: {spec.name}")

            # å¯¼å…¥å·¥å‚æ–¹æ³•ï¼ˆæ¥å£å±‚ï¼Œæ— å¾ªç¯ä¾èµ–ï¼‰
            from pipeline.core.protocols import create_method_handle

            for mname in spec.methods:
                if engine_val == 'auto':
                    h = create_method_handle(spec.component, mname, prefer='auto')
                    handles.append(h)
                else:
                    # æ˜¾å¼å¼•æ“ -> å›ºå®š
                    h = create_method_handle(spec.component, mname, prefer='fixed', fixed_engine=engine_val)
                    handles.append(h)

            # node-level engine å­—æ®µ
            if engine_val == 'auto':
                engine_val = '<handle:auto>'
                self.logger.info(f"ğŸ§· å»¶è¿Ÿç»‘å®šå¼•æ“(å¤šæ–¹æ³•æ”¯æŒ): step={spec.name} methods={spec.methods}")

            node_cfg = {
                'name': spec.name,
                'component': spec.component,
                'engine': engine_val,
                'method': spec.methods if len(spec.methods) > 1 else spec.methods[0],
                'parameters': resolved_params,
                'outputs': node_outs,
                'primary_output': node_outs[0] if node_outs else None
            }

            if handles:
                node_cfg['handles'] = handles

            # æ”¶é›†è¾“å…¥ä¾èµ–
            inputs = []
            for pval in spec.raw_parameters.values():
                for ref in self._extract_refs(pval):
                    m = self.REF_PATTERN.match(ref)
                    if m:
                        ds_in = self.ctx.dataset_name(m.group('step'), m.group('param'))
                        if ds_in not in inputs:
                            inputs.append(ds_in)
            if inputs:
                node_cfg['inputs'] = inputs

            # æ·»åŠ æ˜¾å¼ä¾èµ–ï¼ˆç”¨äº Prefect Engine æ‹“æ‰‘æ’åºï¼‰
            if spec.depends_on:
                node_cfg['depends_on'] = spec.depends_on

            auto_nodes.append(node_cfg)

        # æ›´æ–°é…ç½®
        self.ctx.config.setdefault('pipeline', {}).setdefault('kedro_pipelines', {})['__auto__'] = {
            'description': 'auto-generated from steps list',
            'nodes': auto_nodes
        }

        return {'nodes': auto_nodes}


__all__ = ["ConfigService"]
